{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Setup"
      ],
      "metadata": {
        "id": "S8AUyfLfvgK4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4UVVdEHmvdqg",
        "outputId": "eab48ef9-663e-4335-abcb-e652063245f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.2.2-py3-none-any.whl (346 kB)\n",
            "\u001b[K     |████████████████████████████████| 346 kB 10.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n",
            "Collecting responses<0.19\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.21.6)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0.1)\n",
            "Collecting dill<0.3.5\n",
            "  Downloading dill-0.3.4-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[K     |████████████████████████████████| 86 kB 2.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n",
            "Collecting xxhash\n",
            "  Downloading xxhash-3.0.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[K     |████████████████████████████████| 212 kB 62.1 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub<1.0.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.7.0-py3-none-any.whl (86 kB)\n",
            "\u001b[K     |████████████████████████████████| 86 kB 4.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.11.4)\n",
            "Collecting aiohttp\n",
            "  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 84.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.64.0)\n",
            "Collecting fsspec[http]>=2021.05.0\n",
            "  Downloading fsspec-2022.5.0-py3-none-any.whl (140 kB)\n",
            "\u001b[K     |████████████████████████████████| 140 kB 84.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.13)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.7.0)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 64.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (4.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (3.0.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2022.5.18.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
            "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 70.8 MB/s \n",
            "\u001b[?25hCollecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
            "\u001b[K     |████████████████████████████████| 271 kB 41.2 MB/s \n",
            "\u001b[?25hCollecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n",
            "\u001b[K     |████████████████████████████████| 94 kB 3.2 MB/s \n",
            "\u001b[?25hCollecting asynctest==0.13.0\n",
            "  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n",
            "Collecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.0.12)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "\u001b[K     |████████████████████████████████| 144 kB 65.4 MB/s \n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (21.4.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.8.0)\n",
            "Collecting multiprocess\n",
            "  Downloading multiprocess-0.70.12.2-py37-none-any.whl (112 kB)\n",
            "\u001b[K     |████████████████████████████████| 112 kB 50.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2022.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
            "Installing collected packages: multidict, frozenlist, yarl, urllib3, asynctest, async-timeout, aiosignal, pyyaml, fsspec, dill, aiohttp, xxhash, responses, multiprocess, huggingface-hub, datasets\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Attempting uninstall: dill\n",
            "    Found existing installation: dill 0.3.5.1\n",
            "    Uninstalling dill-0.3.5.1:\n",
            "      Successfully uninstalled dill-0.3.5.1\n",
            "  Attempting uninstall: multiprocess\n",
            "    Found existing installation: multiprocess 0.70.13\n",
            "    Uninstalling multiprocess-0.70.13:\n",
            "      Successfully uninstalled multiprocess-0.70.13\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.2 asynctest-0.13.0 datasets-2.2.2 dill-0.3.4 frozenlist-1.3.0 fsspec-2022.5.0 huggingface-hub-0.7.0 multidict-6.0.2 multiprocess-0.70.12.2 pyyaml-6.0 responses-0.18.0 urllib3-1.25.11 xxhash-3.0.0 yarl-1.7.2\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import list_datasets, load_dataset\n",
        "from transformers import DataCollatorForTokenClassification, AutoTokenizer, AutoModelForTokenClassification, TrainingArguments, Trainer\n",
        "from tensorflow.keras import Model, Input\n",
        "from tensorflow.keras.layers import LSTM, Embedding, Dense, TimeDistributed, SpatialDropout1D, Bidirectional\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from livelossplot.tf_keras import PlotLossesCallback\n",
        "import numpy as np\n",
        "import math\n",
        "import random\n",
        "import copy\n",
        "import tqdm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "mh78XH4AvtXm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data Preparation"
      ],
      "metadata": {
        "id": "-7sgBAaNv9dN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The chosen dataset is from [Hugging face](https://huggingface.co/datasets/nlpaueb/finer-139). <br> It comprises of 1.1M sentences annotated with eXtensive Business Reporting Language (XBRL) tags extracted from annual and quarterly reports of publicly-traded companies in the US. 15k/3.5k/3.5k samples with a maximum length of 64 tokens will be selected from the dataset as train, test and validation data."
      ],
      "metadata": {
        "id": "67UjiaWH1uBn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FinerDataset():\n",
        "\n",
        "    def __init__(self, split_name):\n",
        "      \n",
        "        self.data = {}\n",
        "\n",
        "        dataset = load_dataset(\"nlpaueb/finer-139\", split=split_name)\n",
        "        dataset = dataset.filter((lambda x: len(x[\"tokens\"]) <= 64)) #to set the maximum length of tokens to 64\n",
        "        \n",
        "\n",
        "        if split_name == \"train\":\n",
        "          dataset = dataset.select(range(15000))\n",
        "          \n",
        "        elif (split_name == \"validation\" or split_name == \"test\"):\n",
        "          dataset = dataset.select(range(3500))\n",
        "        \n",
        "\n",
        "\n",
        "        for i in range((len(dataset))):\n",
        "          tokens = dataset[i]['tokens']\n",
        "          y_ners = dataset[i]['ner_tags']\n",
        "          idx = len(self.data)\n",
        "          self.data[idx] = {\n",
        "                            'text': ' '.join(tokens),\n",
        "                            'tokens': tokens, \n",
        "                            'y_ners': y_ners, \n",
        "                            'idx': idx\n",
        "                        }\n",
        "\n",
        "    # We return the length of the dataset\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    # We return the idx'th sample\n",
        "    def __getitem__(self, idx):\n",
        "        return {\n",
        "            'idx': idx,\n",
        "            'word_idx': torch.tensor(self.data[idx]['word_idx']).long(),\n",
        "            'y_ners': torch.tensor(self.data[idx]['y_ners']).long(),\n",
        "            'chars_idx': torch.tensor(self.data[idx]['chars_idx']).long(),\n",
        "        }"
      ],
      "metadata": {
        "id": "D3vDKDjw2hay"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we split the data into train, validate and test"
      ],
      "metadata": {
        "id": "JW9N-SFd2LJ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = FinerDataset(\"train\")\n",
        "val_data = FinerDataset(\"validation\")\n",
        "test_data = FinerDataset(\"test\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303,
          "referenced_widgets": [
            "900c9efa8a0f42fc8e3351a76bd71233",
            "758ed355f7744a6f977c47de37cd2d91",
            "274334985de64b328b9ad4541870fcbb",
            "d88d69d9fcb7476bbb4453d8c6b43538",
            "3bdc5501c76c4819917cd8568ae49405",
            "38049d40b12b47428b6479d5da034699",
            "9e92b351b7aa471bb36489fade2d99de",
            "c58082e248834e7895f3cd6cc4a55116",
            "d0a0b74d49894a15875e7778c00dff78",
            "5189cee10af24219a940a23728111c2f",
            "30963a39a87c43f8bafd2b730b7f094d",
            "fd9c4e7bfcf24891b8ee19c1f850215e",
            "38be5a2fd204464caec6fa784081aecc",
            "7930afbe55cf45b6a0a8bdc7b35ddb31",
            "7ef8219077d34149998725fb9466ca39",
            "09fde6d03ac144d18d02c4f6df966d08",
            "a02a1edd7957405d8b12069c649775d9",
            "6b3b4c9b24ca42fa97fee93878744d01",
            "4768ecc70e124ae58cc5034a978a856a",
            "51058bbb381d467983b0e4206d29bdd0",
            "7e931515d4924ce2ab5ac9aee950702f",
            "64ffbbad15684592a7ab49600403ce86",
            "3b65737c05264b719a90428400d395e3",
            "df1d8cd33b194f77838cbb83bf3e257b",
            "03ac18d6e14a482abe12500f5cfb4dcf",
            "0b1c0d2438094d12aba6986b29b924d1",
            "19b429de33944265a51acfb5ea156257",
            "dc7f4cf821a447e08d10cb959b73f1ea",
            "bde68c5e19504c4cae3b0a9791988c40",
            "0c7880d2e8fa475cb73edf0e30ca0f4f",
            "ed101f3f0e2d4221b218cbd77c311259",
            "73bd597f5be542718d150a22842e3eed",
            "411396e9a9ab40d4b05a9fed2483b5fc",
            "c1b3fff303f448c1aaad4586198dacf4",
            "4fac062cfb1c4823bfd57fa4315cd04e",
            "9dbd182420a34a29a7fd3c07c899d4af",
            "8a163b6712274e9e889ad336796fb11c",
            "478e1b1b3524498f9a88e4b6e625d0e2",
            "38b64a063db245f0b42672c4f5a67b00",
            "0c081bcc72b847f989c8b517d4057312",
            "62a2e9d1df904a9a9fa6ee7c91b3ed70",
            "e6406874a8e14744bb678d9777f73710",
            "e832b16749f040c6ad76dd134c15016b",
            "f5f890073d3c45e797646384a3e9bc00",
            "202ab0ad9c4048a283288684c5404e0a",
            "e82a77b2c6ff46c8a566881e1dc1f84f",
            "60ed6dc1b04f4cc8803445cd51643468",
            "26ae53b725f24eb395f4798721fd547d",
            "6e3552ce6d384923b95dd2c396f25fb6",
            "eadf96677b7944d5990e505618766af7",
            "30a1b02095724eaf9956f3b1702fed80",
            "387d441af5c14f8e915b7bb226450254",
            "3d1e1062825b4c60aca63912a3d35369",
            "c740d17fcfa54160aa24539f942ae032",
            "5b73fa2d3bee49c893841db2991e2d8b",
            "7b887537808c424698533288467838f1",
            "597bc501972c4446b45717d80b57bee5",
            "7f766db7b3a5478b9c38b1e5d7a298b8",
            "08b3dfda0a85472d8ca0dc831dd4c53b",
            "a014796b7e5e4f87bb0a9437ddeff55b",
            "595ac040759b44939a98f65402aee110",
            "b058af9b258f49729b1dd67510555f2d",
            "ba16cd566d02454aa64189322a992c1a",
            "2ef9f65329e7427c9f708df4061e6dfe",
            "a4b593c30003434d8336f8117db59246",
            "3bc1a963196e4dfc9aee9ace7c0ddb1a",
            "07597bfef06a4898b2ae2c579bcea4cd",
            "337aa389d88a48179fcd3ec806108b4a",
            "22e75c12f39f456e9877621c11dd9c00",
            "67179d26ec7b4a74b6e76fa589be972e",
            "b5a8b09cc8504acf9fae4ee989af7dc9",
            "50854fcaed6343d9ab129c8e620c650e",
            "5e4b4c84cc994ca29f53b3148992d60e",
            "4499dc682cf9401ca4a7ae6d839d716c",
            "ca3a05dd2e1b4313910ee18d3818ab8e",
            "d639d24b9c4f415d90d1c157448e1ff1",
            "d7302479cf9344a59cc651ede1685830",
            "f4f85440a2424567b2b35b7bfa2075db",
            "52896702d15d4c68b498900a87907613",
            "646648ed13384d6f980b740c2d4daf2d",
            "c61d33ed4e5d42fb97c784b4537365b0",
            "364ee22f2547494da245ba61b682a36e",
            "b94d245468794f5ba2e9ba0e5cd42aec",
            "1e1e1b4693ad42128c2574fd6000b975",
            "5f001045bb1d4da5a0e575241e6514c5",
            "d6f0518c7ca8441fa47c890b0319c8a5",
            "22dda4739d7540f887b901cdda7db26d",
            "97b7a5b80e5348f9a8236fbd2709c63b",
            "21fb245bbbf14641b252ff7ed1aadbdc",
            "69aeedfb540041a6a1b78a7a5dc81f94",
            "a1a92ddcb28740f187a00c1171017eaf",
            "7f34e84685674ce9876ce037d4cf1210",
            "ada9d0dcd6c4427abd7a9d60dfe66fce",
            "52789f9fff44425eb4df0d47c46bfa14",
            "80202a7e0b8544e6accfd343735e94ae",
            "a44a515905ba4a9b8de9d65b60d66c50",
            "615a1b84ad214111982f471379dfb209",
            "b4bcc813e02440c9a80bf5e0e1a8ac41",
            "6dbe58ebac7d4613b15e1003a23f43b8"
          ]
        },
        "id": "EeFQNidM2NX6",
        "outputId": "6da006be-a7a9-4a81-9603-9c695184d09a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/19.1k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "900c9efa8a0f42fc8e3351a76bd71233"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading metadata:   0%|          | 0.00/15.9k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fd9c4e7bfcf24891b8ee19c1f850215e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading and preparing dataset finer139/finer-139 (download: 98.42 MiB, generated: 824.09 MiB, post-processed: Unknown size, total: 922.51 MiB) to /root/.cache/huggingface/datasets/nlpaueb___finer139/finer-139/1.0.0/5f5a8eb2a38e8b142bb8ca63f3f9600634cc6c8963e4c982926cf2b48e4e55ff...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/103M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3b65737c05264b719a90428400d395e3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/900384 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c1b3fff303f448c1aaad4586198dacf4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating validation split:   0%|          | 0/112494 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "202ab0ad9c4048a283288684c5404e0a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating test split:   0%|          | 0/108378 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7b887537808c424698533288467838f1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset finer139 downloaded and prepared to /root/.cache/huggingface/datasets/nlpaueb___finer139/finer-139/1.0.0/5f5a8eb2a38e8b142bb8ca63f3f9600634cc6c8963e4c982926cf2b48e4e55ff. Subsequent calls will reuse this data.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/901 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "07597bfef06a4898b2ae2c579bcea4cd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Reusing dataset finer139 (/root/.cache/huggingface/datasets/nlpaueb___finer139/finer-139/1.0.0/5f5a8eb2a38e8b142bb8ca63f3f9600634cc6c8963e4c982926cf2b48e4e55ff)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/113 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f4f85440a2424567b2b35b7bfa2075db"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Reusing dataset finer139 (/root/.cache/huggingface/datasets/nlpaueb___finer139/finer-139/1.0.0/5f5a8eb2a38e8b142bb8ca63f3f9600634cc6c8963e4c982926cf2b48e4e55ff)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/109 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "21fb245bbbf14641b252ff7ed1aadbdc"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#check the length of the data\n",
        "len(train_data), len(val_data), len(test_data) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QO8yfmY133GA",
        "outputId": "3b6664ec-3875-4199-f805-5cd1e0252b13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(15000, 3500, 3500)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set seeds for reproducibility\n",
        "SEED = 42\n",
        "torch.manual_seed(SEED)\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)"
      ],
      "metadata": {
        "id": "-k4ZVa4fwU1W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocabulary = set()\n",
        "for idx, sample in train_data.data.items(): # Pay attention we only use the training set!\n",
        "  for token in sample['tokens']:\n",
        "    vocabulary.add(token)\n",
        "len(vocabulary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I-1BoOVis2u_",
        "outputId": "ce6716f3-e9c9-4050-ac75-93396994e4f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11556"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the mappindg word - index and vice-versa\n",
        "word2idx = {'_PAD_': 0, '_UNK_': 1}\n",
        "for word in vocabulary:\n",
        "  word2idx[word] = len(word2idx)\n",
        "idx2word = {idx:word for word, idx in word2idx.items()}\n",
        "word2idx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4SKTYaDXszBp",
        "outputId": "44c74298-8b67-4870-b5cf-f1acb509436d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'_PAD_': 0,\n",
              " '_UNK_': 1,\n",
              " '': 2,\n",
              " 'Share': 3,\n",
              " 'grant': 4,\n",
              " 'Codification': 5,\n",
              " 'Subpoenas': 6,\n",
              " 'computation': 7,\n",
              " '2,250,360': 8,\n",
              " 'Catterton': 9,\n",
              " '40.0': 10,\n",
              " '0.5632': 11,\n",
              " '242,068': 12,\n",
              " 'Turnaround': 13,\n",
              " 'Ms.': 14,\n",
              " 'GENERATORS': 15,\n",
              " 'Stapleton': 16,\n",
              " 'Appreciation': 17,\n",
              " 'Raising': 18,\n",
              " 'HPE': 19,\n",
              " 'borrowed': 20,\n",
              " 'C-15': 21,\n",
              " '4,173,014': 22,\n",
              " '253': 23,\n",
              " 'Parcel': 24,\n",
              " 'wrote': 25,\n",
              " 'Purpose': 26,\n",
              " '40.1': 27,\n",
              " '6,279': 28,\n",
              " '21,600': 29,\n",
              " 'reputation': 30,\n",
              " '776,000': 31,\n",
              " 'PLANT': 32,\n",
              " 'Legacy': 33,\n",
              " 'Commercial': 34,\n",
              " 'Firm': 35,\n",
              " '5,932': 36,\n",
              " 'braking': 37,\n",
              " 'fraudulent': 38,\n",
              " 'Inflation': 39,\n",
              " 'incur': 40,\n",
              " 'outputs': 41,\n",
              " 'work': 42,\n",
              " 'Connecticut': 43,\n",
              " '500,000,000': 44,\n",
              " 'fixed': 45,\n",
              " 'Provision': 46,\n",
              " 'Warrants': 47,\n",
              " '11.8': 48,\n",
              " 'Sarl': 49,\n",
              " '8,580': 50,\n",
              " '13.1': 51,\n",
              " 'group': 52,\n",
              " 'online': 53,\n",
              " 'confirm': 54,\n",
              " '76.9': 55,\n",
              " 'ENERGY': 56,\n",
              " 'prioritizes': 57,\n",
              " '26.4': 58,\n",
              " '3Consolidated': 59,\n",
              " 'interchange': 60,\n",
              " 'entire': 61,\n",
              " 'equates': 62,\n",
              " 'ordinary': 63,\n",
              " 'Impaired': 64,\n",
              " '7,573': 65,\n",
              " '171,135': 66,\n",
              " '0.225': 67,\n",
              " 'ESPP': 68,\n",
              " '294,574': 69,\n",
              " 'unenforceability': 70,\n",
              " 'deemed': 71,\n",
              " 'patients': 72,\n",
              " 'gain': 73,\n",
              " '23,817': 74,\n",
              " 'reliefs': 75,\n",
              " '2018': 76,\n",
              " 'notes': 77,\n",
              " '2.84': 78,\n",
              " 'actuaries': 79,\n",
              " '17.00': 80,\n",
              " 'TRSs': 81,\n",
              " '372,475': 82,\n",
              " 'performing': 83,\n",
              " 'rehearing': 84,\n",
              " 'Dr.': 85,\n",
              " 'Introduction': 86,\n",
              " 'LGM': 87,\n",
              " 'ultimate': 88,\n",
              " 'thus': 89,\n",
              " 'pronouncement': 90,\n",
              " 'Miscellaneous': 91,\n",
              " 'presents': 92,\n",
              " '2,131,290': 93,\n",
              " 'My': 94,\n",
              " 'accordingly': 95,\n",
              " 'forth': 96,\n",
              " 'commodity': 97,\n",
              " '165,000': 98,\n",
              " 'adds': 99,\n",
              " '28.3': 100,\n",
              " 'Simultaneously': 101,\n",
              " '14,812': 102,\n",
              " 'none': 103,\n",
              " 'treaty': 104,\n",
              " '119': 105,\n",
              " 'fromthree': 106,\n",
              " 'Tail': 107,\n",
              " 'Daoud': 108,\n",
              " '1': 109,\n",
              " '188,383': 110,\n",
              " 'air': 111,\n",
              " 'Resource': 112,\n",
              " 'Cameron': 113,\n",
              " 'projected': 114,\n",
              " 'utilizes': 115,\n",
              " 'category': 116,\n",
              " '40,725': 117,\n",
              " 'SPAR': 118,\n",
              " 'unexpired': 119,\n",
              " 'later': 120,\n",
              " 'exploration': 121,\n",
              " 'subtopic': 122,\n",
              " 'outside': 123,\n",
              " 'Earned': 124,\n",
              " '2029': 125,\n",
              " 'foot': 126,\n",
              " 'reasonably': 127,\n",
              " '2034': 128,\n",
              " 'Little': 129,\n",
              " 'requirements': 130,\n",
              " 'AOCL': 131,\n",
              " '2,150,000': 132,\n",
              " '0.86': 133,\n",
              " 'eventual': 134,\n",
              " 'raw': 135,\n",
              " 'OTHER': 136,\n",
              " '17th': 137,\n",
              " 'exercised': 138,\n",
              " 'Tisnado': 139,\n",
              " 'note': 140,\n",
              " 'interests': 141,\n",
              " 'governments': 142,\n",
              " '805': 143,\n",
              " 'rule': 144,\n",
              " '1.89': 145,\n",
              " 'receiving': 146,\n",
              " 'Basic': 147,\n",
              " 'roofing': 148,\n",
              " '\\uf0b7Common': 149,\n",
              " '100.5': 150,\n",
              " 'accountants': 151,\n",
              " 'administration': 152,\n",
              " 'Equipment': 153,\n",
              " 'conducting': 154,\n",
              " 'smart': 155,\n",
              " '560,000': 156,\n",
              " 'Regulation': 157,\n",
              " 'workers': 158,\n",
              " 'original': 159,\n",
              " 'widespread': 160,\n",
              " 'technical': 161,\n",
              " '114': 162,\n",
              " '32,796': 163,\n",
              " 'noodle': 164,\n",
              " 'Interconnect': 165,\n",
              " 'Contents': 166,\n",
              " 'consolidate': 167,\n",
              " '138,750': 168,\n",
              " 'referral': 169,\n",
              " '855': 170,\n",
              " 'Alinda': 171,\n",
              " 'Duavive': 172,\n",
              " 'Actual': 173,\n",
              " 'raise': 174,\n",
              " 'trespass': 175,\n",
              " 'worked': 176,\n",
              " '32,734': 177,\n",
              " 'course': 178,\n",
              " '08CV5942': 179,\n",
              " 'implement': 180,\n",
              " 'annuities': 181,\n",
              " 'multiplying': 182,\n",
              " 'Unaoil': 183,\n",
              " 'OPERATIONSSummaryThe': 184,\n",
              " '1250': 185,\n",
              " '49.01': 186,\n",
              " 'distributions': 187,\n",
              " 'Room': 188,\n",
              " 'allegations': 189,\n",
              " '14.33': 190,\n",
              " 'Restricted': 191,\n",
              " 'FISC': 192,\n",
              " 'Affiliated': 193,\n",
              " 'matter': 194,\n",
              " 'freely': 195,\n",
              " 'sublease': 196,\n",
              " 'shipments': 197,\n",
              " 'Established': 198,\n",
              " '25': 199,\n",
              " 'lives': 200,\n",
              " 'week': 201,\n",
              " 'betweenthree': 202,\n",
              " 'IRBs': 203,\n",
              " 'FLOWS6': 204,\n",
              " 'closing': 205,\n",
              " 'inclusion': 206,\n",
              " 'enable': 207,\n",
              " 'statutes': 208,\n",
              " 'Fin': 209,\n",
              " 'Study': 210,\n",
              " 'cashless': 211,\n",
              " 'accounted': 212,\n",
              " 'separately': 213,\n",
              " '49,261': 214,\n",
              " 'remainder': 215,\n",
              " 'steroidal': 216,\n",
              " '5B': 217,\n",
              " 'Boardwalk': 218,\n",
              " 'GOING': 219,\n",
              " 'closeout': 220,\n",
              " 'office': 221,\n",
              " '29': 222,\n",
              " 'point': 223,\n",
              " 'Calico': 224,\n",
              " 'Sharing': 225,\n",
              " 'GPD': 226,\n",
              " 'depreciated': 227,\n",
              " 'anticipated': 228,\n",
              " 'months': 229,\n",
              " 'ago': 230,\n",
              " '25,000': 231,\n",
              " '1ST': 232,\n",
              " 'Receiver': 233,\n",
              " 'Rio': 234,\n",
              " 'One': 235,\n",
              " 'vibration': 236,\n",
              " 'Of': 237,\n",
              " '300.7': 238,\n",
              " '206.9': 239,\n",
              " '49.7': 240,\n",
              " 'PCI': 241,\n",
              " 'Matter': 242,\n",
              " '5701': 243,\n",
              " 'Payables': 244,\n",
              " 'media': 245,\n",
              " 'contracted': 246,\n",
              " 'Rhode': 247,\n",
              " 'Waterbury': 248,\n",
              " 'homeowners': 249,\n",
              " '318': 250,\n",
              " 'MOU': 251,\n",
              " 'consistently': 252,\n",
              " 'obvious': 253,\n",
              " 'FY18': 254,\n",
              " '818.5': 255,\n",
              " '326': 256,\n",
              " 'treated': 257,\n",
              " '44,717': 258,\n",
              " 'eminent': 259,\n",
              " '9,400': 260,\n",
              " 'consistency': 261,\n",
              " 'sheet': 262,\n",
              " 'minimis': 263,\n",
              " 'uplisted': 264,\n",
              " 'DPPL': 265,\n",
              " 'directors': 266,\n",
              " '1.4': 267,\n",
              " '1,923': 268,\n",
              " 'specialists': 269,\n",
              " '75': 270,\n",
              " 'Updates': 271,\n",
              " 'unconditional': 272,\n",
              " '3303': 273,\n",
              " 'increase': 274,\n",
              " 'sustained': 275,\n",
              " 'Exploration': 276,\n",
              " '132,000': 277,\n",
              " 'pledged': 278,\n",
              " 'exclusive': 279,\n",
              " 'capitalizes': 280,\n",
              " 'Machinists': 281,\n",
              " '26.9': 282,\n",
              " 'impaired': 283,\n",
              " 'Rights': 284,\n",
              " 'negotiations': 285,\n",
              " 'INVESTMENTS': 286,\n",
              " '498,707': 287,\n",
              " 'feature': 288,\n",
              " 'Reportable': 289,\n",
              " 'Summarized': 290,\n",
              " 'structured': 291,\n",
              " 'auction': 292,\n",
              " '99.94': 293,\n",
              " 'buyer': 294,\n",
              " 'Phase': 295,\n",
              " '8-K': 296,\n",
              " 'VEBA': 297,\n",
              " 'Judicial': 298,\n",
              " 'solution': 299,\n",
              " 'reserves': 300,\n",
              " 'Cache': 301,\n",
              " 'Treatment': 302,\n",
              " 'NAEI': 303,\n",
              " 'analyzes': 304,\n",
              " 'rationalization': 305,\n",
              " 'Sensitivity': 306,\n",
              " '33,000': 307,\n",
              " 'nuisance': 308,\n",
              " '57,784': 309,\n",
              " 'offered': 310,\n",
              " '50-Table': 311,\n",
              " '583,333': 312,\n",
              " 'optimize': 313,\n",
              " 'FPC': 314,\n",
              " '107.46': 315,\n",
              " '54.1': 316,\n",
              " 'up': 317,\n",
              " 'Quarter': 318,\n",
              " 'unexercised': 319,\n",
              " '62.0': 320,\n",
              " '109,000': 321,\n",
              " '10,161': 322,\n",
              " 'simplify': 323,\n",
              " 'points': 324,\n",
              " '120.0': 325,\n",
              " '1.0': 326,\n",
              " 'violated': 327,\n",
              " 'kilometers': 328,\n",
              " '2,048,000': 329,\n",
              " 'Guidance': 330,\n",
              " '23,068': 331,\n",
              " 'Belvieu': 332,\n",
              " 'alone': 333,\n",
              " 'treasury': 334,\n",
              " 'RECEIVABLE': 335,\n",
              " 'Jim': 336,\n",
              " 'Science': 337,\n",
              " 'Degree': 338,\n",
              " 'Tower': 339,\n",
              " 'sufficiently': 340,\n",
              " 'allegation': 341,\n",
              " 'items': 342,\n",
              " 'categorized': 343,\n",
              " 'clean': 344,\n",
              " 'import': 345,\n",
              " '1967': 346,\n",
              " 'unvested': 347,\n",
              " 'difficulty': 348,\n",
              " '4.750': 349,\n",
              " 'warrant': 350,\n",
              " '58.0': 351,\n",
              " 'variability': 352,\n",
              " 'compliant': 353,\n",
              " 'reduction': 354,\n",
              " 'Transmissions': 355,\n",
              " 'subcontract': 356,\n",
              " 'opposed': 357,\n",
              " 'principal': 358,\n",
              " 'Dusseldorf': 359,\n",
              " 'presently': 360,\n",
              " 'pass': 361,\n",
              " '15c3': 362,\n",
              " 'funding': 363,\n",
              " 'AG': 364,\n",
              " 'peers': 365,\n",
              " 'vacant': 366,\n",
              " 'commercial': 367,\n",
              " 'Grants': 368,\n",
              " 'MET': 369,\n",
              " 'B.': 370,\n",
              " '3,419': 371,\n",
              " 'lawsuit': 372,\n",
              " 'Cooperative': 373,\n",
              " 'Entity': 374,\n",
              " 'Finserv': 375,\n",
              " 'Deferred': 376,\n",
              " 'lessors': 377,\n",
              " '17,749,756': 378,\n",
              " 'many': 379,\n",
              " 'Prepaid': 380,\n",
              " 'adopting': 381,\n",
              " 'SHEETS': 382,\n",
              " 'Workers': 383,\n",
              " 'sulfur': 384,\n",
              " 'biphenyls': 385,\n",
              " 'increasing': 386,\n",
              " '6,296,805': 387,\n",
              " 'Army': 388,\n",
              " 'hereto': 389,\n",
              " 'real': 390,\n",
              " 'Heat': 391,\n",
              " 'meetings': 392,\n",
              " 'southeast': 393,\n",
              " '678,000': 394,\n",
              " 'Equivalents': 395,\n",
              " 'decision': 396,\n",
              " '21.4': 397,\n",
              " 'period': 398,\n",
              " '8.2': 399,\n",
              " 'Board': 400,\n",
              " 'classifications': 401,\n",
              " 'k': 402,\n",
              " 'Allocation': 403,\n",
              " 'engaged': 404,\n",
              " '31.1': 405,\n",
              " '1,270.5': 406,\n",
              " 'Since': 407,\n",
              " 'manages': 408,\n",
              " 'disclosure': 409,\n",
              " 'broaden': 410,\n",
              " 'upholding': 411,\n",
              " 'Debts': 412,\n",
              " 'matured': 413,\n",
              " 'discounting': 414,\n",
              " 'capitalization': 415,\n",
              " 'issuances': 416,\n",
              " 'insured': 417,\n",
              " 'Landfill': 418,\n",
              " 'tested': 419,\n",
              " 'qualification': 420,\n",
              " 'valuing': 421,\n",
              " 'spaces': 422,\n",
              " 'confirmed': 423,\n",
              " 'Complaints': 424,\n",
              " 'votes': 425,\n",
              " '1,421': 426,\n",
              " 'Represents': 427,\n",
              " 'EVP': 428,\n",
              " 'BNBS': 429,\n",
              " 'discount': 430,\n",
              " 'cv': 431,\n",
              " '18.1': 432,\n",
              " 'Could': 433,\n",
              " '1.3': 434,\n",
              " 'concern': 435,\n",
              " 'barges': 436,\n",
              " 'Liquidated': 437,\n",
              " 'invalidating': 438,\n",
              " 'placeshifting': 439,\n",
              " 'below': 440,\n",
              " 'Lovejoy': 441,\n",
              " 'corrected': 442,\n",
              " 'SAP': 443,\n",
              " 'Utilities': 444,\n",
              " 'major': 445,\n",
              " 'Blount': 446,\n",
              " 'consideration': 447,\n",
              " 'A-2-III': 448,\n",
              " 'designating': 449,\n",
              " '334,119': 450,\n",
              " '5.48': 451,\n",
              " 'pre': 452,\n",
              " 'interdependent': 453,\n",
              " '11.5': 454,\n",
              " '643.7': 455,\n",
              " '22-Table': 456,\n",
              " 'Important': 457,\n",
              " 'INCOMING': 458,\n",
              " 'Langenohl': 459,\n",
              " 'fabricating': 460,\n",
              " 'report': 461,\n",
              " 'withholds': 462,\n",
              " 'footnotes': 463,\n",
              " 'Monte': 464,\n",
              " 'PART': 465,\n",
              " '28.1': 466,\n",
              " 'variation': 467,\n",
              " 'Multifamily': 468,\n",
              " '341': 469,\n",
              " 'uncollectible': 470,\n",
              " '360,000': 471,\n",
              " 'joint': 472,\n",
              " '16,393': 473,\n",
              " 'Venlafaxine': 474,\n",
              " 'adjustment': 475,\n",
              " 'emission': 476,\n",
              " 'minimum': 477,\n",
              " '483,333': 478,\n",
              " '60': 479,\n",
              " 'LEP': 480,\n",
              " 'Kay': 481,\n",
              " 'calendar': 482,\n",
              " 'distributors': 483,\n",
              " '131.7': 484,\n",
              " '16.9': 485,\n",
              " 'excess': 486,\n",
              " 'ruled': 487,\n",
              " 'lock': 488,\n",
              " 'Initiatives': 489,\n",
              " 'Energo': 490,\n",
              " 'conduit': 491,\n",
              " 'consist': 492,\n",
              " '1,352.0': 493,\n",
              " 'passed': 494,\n",
              " 'inclusive': 495,\n",
              " 'effectiveness': 496,\n",
              " 'VENDOR': 497,\n",
              " 'mineral': 498,\n",
              " 'Rule': 499,\n",
              " 'bonus': 500,\n",
              " '9.026': 501,\n",
              " 'Given': 502,\n",
              " 'savings': 503,\n",
              " 'irrevocably': 504,\n",
              " 'Subordinated': 505,\n",
              " 'barred': 506,\n",
              " 'S-8': 507,\n",
              " '8.1': 508,\n",
              " 'Six': 509,\n",
              " 'projection': 510,\n",
              " 'Competition': 511,\n",
              " '08': 512,\n",
              " 'absorb': 513,\n",
              " 'Retained': 514,\n",
              " 'Pooling': 515,\n",
              " 'effect': 516,\n",
              " 'Risk': 517,\n",
              " 'M': 518,\n",
              " 'Sheridan': 519,\n",
              " 'both': 520,\n",
              " 'asphalt': 521,\n",
              " '134.7': 522,\n",
              " '3,140': 523,\n",
              " 'Procedurally': 524,\n",
              " 'capped': 525,\n",
              " 'Ku': 526,\n",
              " 'Western': 527,\n",
              " 'Participating': 528,\n",
              " '35.2': 529,\n",
              " 'wide': 530,\n",
              " 'declaratory': 531,\n",
              " 'rulings': 532,\n",
              " 'marked': 533,\n",
              " 'sales': 534,\n",
              " 'election': 535,\n",
              " 'composition': 536,\n",
              " 'Definite': 537,\n",
              " 'Positive': 538,\n",
              " 'encourages': 539,\n",
              " 'Ticket': 540,\n",
              " 'P': 541,\n",
              " 'Pizza': 542,\n",
              " 'Toviaz': 543,\n",
              " 'restates': 544,\n",
              " 'TSA': 545,\n",
              " 'arguments': 546,\n",
              " '20': 547,\n",
              " 'misconduct': 548,\n",
              " 'foreseeable': 549,\n",
              " 'Works': 550,\n",
              " 'instances': 551,\n",
              " '5,880,000': 552,\n",
              " '0.3': 553,\n",
              " 'Cleveland': 554,\n",
              " '72.5': 555,\n",
              " 'covering': 556,\n",
              " '180': 557,\n",
              " '4.6': 558,\n",
              " 'Licensing': 559,\n",
              " 'concentrated': 560,\n",
              " '85.0': 561,\n",
              " '91.5': 562,\n",
              " 'provisionally': 563,\n",
              " 'circumvent': 564,\n",
              " '1,806,253': 565,\n",
              " '170.9': 566,\n",
              " 'map': 567,\n",
              " '2,693': 568,\n",
              " 'guaranty': 569,\n",
              " 'MOBs': 570,\n",
              " 'bridge': 571,\n",
              " 'consequently': 572,\n",
              " 'subscribed': 573,\n",
              " 'vehicles': 574,\n",
              " '221,000': 575,\n",
              " 'committed': 576,\n",
              " 'Guarantees': 577,\n",
              " 'SUPPLEMENTAL': 578,\n",
              " '50,000': 579,\n",
              " 'deems': 580,\n",
              " 'certified': 581,\n",
              " '128.7': 582,\n",
              " '83,000': 583,\n",
              " 'continue': 584,\n",
              " '6,667': 585,\n",
              " 'regulations': 586,\n",
              " '3.52': 587,\n",
              " 'Paz': 588,\n",
              " '262.5': 589,\n",
              " 'Shareholders': 590,\n",
              " '51,015': 591,\n",
              " 'conveyed': 592,\n",
              " 'Holders': 593,\n",
              " 'acreage': 594,\n",
              " '0.5120': 595,\n",
              " '1,218.8': 596,\n",
              " 'Del': 597,\n",
              " '656.1': 598,\n",
              " 'bull': 599,\n",
              " 'NCWD': 600,\n",
              " 'immediately': 601,\n",
              " 'begins': 602,\n",
              " 'evaluating': 603,\n",
              " 'default': 604,\n",
              " 'ENDED': 605,\n",
              " 'tendered': 606,\n",
              " 'personnel': 607,\n",
              " 'register': 608,\n",
              " 'ACQUISITIONS': 609,\n",
              " 'L.P.Consolidated': 610,\n",
              " 'Leasing': 611,\n",
              " '22,139': 612,\n",
              " 'evaluated': 613,\n",
              " 'who': 614,\n",
              " 'predictable': 615,\n",
              " 'Pamela': 616,\n",
              " 'deferrals': 617,\n",
              " 'additionally': 618,\n",
              " 'acquire': 619,\n",
              " 'remain': 620,\n",
              " 'Conversion': 621,\n",
              " 'brought': 622,\n",
              " 'Anomalies': 623,\n",
              " 'stocks': 624,\n",
              " 'Storage': 625,\n",
              " 'extinguishment': 626,\n",
              " 'SEMPRA': 627,\n",
              " 'Dollars': 628,\n",
              " 'Term': 629,\n",
              " 'Issuers': 630,\n",
              " 'project': 631,\n",
              " 'Section': 632,\n",
              " 'severities': 633,\n",
              " 'relation': 634,\n",
              " 'provider': 635,\n",
              " 'ramifications': 636,\n",
              " 'chart': 637,\n",
              " 'equator': 638,\n",
              " 'PDE-4': 639,\n",
              " 'BANK': 640,\n",
              " 'improving': 641,\n",
              " '1:13': 642,\n",
              " 'intangibles': 643,\n",
              " 'radio': 644,\n",
              " '333.7': 645,\n",
              " 'Blvd': 646,\n",
              " 'indemnify': 647,\n",
              " '8.3': 648,\n",
              " 'redeemed': 649,\n",
              " 'dish': 650,\n",
              " 'introducing': 651,\n",
              " 'Lenoir': 652,\n",
              " '226,465': 653,\n",
              " 'modeling': 654,\n",
              " 'comprise': 655,\n",
              " 'FLOWS': 656,\n",
              " 'Terms': 657,\n",
              " 'Century': 658,\n",
              " 'headquartered': 659,\n",
              " 'withhold': 660,\n",
              " 'Relative': 661,\n",
              " 'clearly': 662,\n",
              " 'Kaustav': 663,\n",
              " 'DNLLC': 664,\n",
              " 'pumps': 665,\n",
              " 'UN': 666,\n",
              " '119,947': 667,\n",
              " 'merchant': 668,\n",
              " '9,772': 669,\n",
              " 'cleared': 670,\n",
              " 'acquired': 671,\n",
              " 'Echols': 672,\n",
              " 'PTO': 673,\n",
              " 'achieve': 674,\n",
              " 'advance': 675,\n",
              " '30day': 676,\n",
              " 'stored': 677,\n",
              " '2016.3': 678,\n",
              " 'Current': 679,\n",
              " '36.5': 680,\n",
              " '9,650': 681,\n",
              " 'Anderson': 682,\n",
              " 'month': 683,\n",
              " '34.2': 684,\n",
              " 'informs': 685,\n",
              " 'assumption': 686,\n",
              " '2025': 687,\n",
              " 'tracking': 688,\n",
              " 'Manufacturas': 689,\n",
              " 'Until': 690,\n",
              " 'oversight': 691,\n",
              " 'exhaustion': 692,\n",
              " 'Additionally': 693,\n",
              " 'much': 694,\n",
              " 'wealth': 695,\n",
              " 'selecting': 696,\n",
              " 'catastrophes': 697,\n",
              " '17,621': 698,\n",
              " 'Panthur': 699,\n",
              " 'inconsistency': 700,\n",
              " 'Home': 701,\n",
              " '82.0': 702,\n",
              " 'house': 703,\n",
              " 'Otherwise': 704,\n",
              " 'inactive': 705,\n",
              " 'footage': 706,\n",
              " '420.3': 707,\n",
              " 'Maximum': 708,\n",
              " 'Series': 709,\n",
              " '3.30': 710,\n",
              " '7.375': 711,\n",
              " 'demand': 712,\n",
              " 'Variable': 713,\n",
              " 'tams': 714,\n",
              " 'Nutrition': 715,\n",
              " '111': 716,\n",
              " 'home': 717,\n",
              " 'Arrangements': 718,\n",
              " 'Redspin': 719,\n",
              " 'decide': 720,\n",
              " 'HIS': 721,\n",
              " 'Asia': 722,\n",
              " 'sources': 723,\n",
              " 'caption': 724,\n",
              " '13.9': 725,\n",
              " '2,575': 726,\n",
              " 'Detroiters': 727,\n",
              " '010875-CE': 728,\n",
              " 'lacked': 729,\n",
              " '23.7': 730,\n",
              " 'seq': 731,\n",
              " 'Consulting': 732,\n",
              " '4.25': 733,\n",
              " 'reassignment': 734,\n",
              " 'preceding': 735,\n",
              " 'brings': 736,\n",
              " 'president': 737,\n",
              " 'ribbed': 738,\n",
              " 'CONCERN': 739,\n",
              " '300': 740,\n",
              " '2036': 741,\n",
              " 'obtains': 742,\n",
              " '1:13-cv-00686': 743,\n",
              " '670,256': 744,\n",
              " 'analyzing': 745,\n",
              " 'Valley': 746,\n",
              " '2,290,586': 747,\n",
              " 'Complaint': 748,\n",
              " '57.8': 749,\n",
              " 'USA': 750,\n",
              " 'earn': 751,\n",
              " '6.53': 752,\n",
              " 'campus': 753,\n",
              " '750': 754,\n",
              " 'still': 755,\n",
              " 'mainly': 756,\n",
              " 'reissue': 757,\n",
              " 'conducted': 758,\n",
              " 'officer': 759,\n",
              " 'Passenger': 760,\n",
              " 'Communications': 761,\n",
              " 'homesite': 762,\n",
              " 'RSU': 763,\n",
              " '13.7': 764,\n",
              " 'Q': 765,\n",
              " '214.0': 766,\n",
              " 'Mission': 767,\n",
              " '321,750': 768,\n",
              " 'TdM': 769,\n",
              " 'amortizes': 770,\n",
              " '840': 771,\n",
              " 'Earth': 772,\n",
              " '18': 773,\n",
              " 'metric': 774,\n",
              " '67.2': 775,\n",
              " 'Levi': 776,\n",
              " 'Signal': 777,\n",
              " 'collateralizing': 778,\n",
              " 'SERP': 779,\n",
              " 'relations': 780,\n",
              " 'Coax': 781,\n",
              " '2,300': 782,\n",
              " 'Brazilian': 783,\n",
              " 'engine': 784,\n",
              " 'coliform': 785,\n",
              " 'expires': 786,\n",
              " 'Offsetting': 787,\n",
              " '312': 788,\n",
              " '58.1': 789,\n",
              " 'Orleans': 790,\n",
              " 'buildings': 791,\n",
              " '20.0': 792,\n",
              " 'THE': 793,\n",
              " '338,000': 794,\n",
              " '2': 795,\n",
              " '0.22': 796,\n",
              " 'warranties': 797,\n",
              " 'consequences': 798,\n",
              " 'majority': 799,\n",
              " 'refocus': 800,\n",
              " 'Regular': 801,\n",
              " '30.9': 802,\n",
              " 'startup': 803,\n",
              " '14-Deferred': 804,\n",
              " 'distress': 805,\n",
              " '39': 806,\n",
              " 'degree': 807,\n",
              " 'sub': 808,\n",
              " 'commensurate': 809,\n",
              " 'reports': 810,\n",
              " 'offsets': 811,\n",
              " 'remediation': 812,\n",
              " 'great': 813,\n",
              " 'Protocol': 814,\n",
              " '83,720': 815,\n",
              " 'Recoupable': 816,\n",
              " 'prepaid': 817,\n",
              " 'ceded': 818,\n",
              " 'weakness': 819,\n",
              " '15,002': 820,\n",
              " 'History': 821,\n",
              " 'CAP': 822,\n",
              " '22,000': 823,\n",
              " 'even': 824,\n",
              " 'presented': 825,\n",
              " '652': 826,\n",
              " 'Virgin': 827,\n",
              " '10.5': 828,\n",
              " 'consumables': 829,\n",
              " '35.1': 830,\n",
              " 'Korsinsky': 831,\n",
              " 'denied': 832,\n",
              " '1,103,850': 833,\n",
              " 'barrels': 834,\n",
              " '772.8': 835,\n",
              " 'Accrued': 836,\n",
              " 'Decree': 837,\n",
              " 'subscriber': 838,\n",
              " 'OVEN': 839,\n",
              " 'Technologies': 840,\n",
              " '31-Table': 841,\n",
              " 'non': 842,\n",
              " '22.4': 843,\n",
              " 'Lender': 844,\n",
              " 'Droplet': 845,\n",
              " '37.55': 846,\n",
              " '730': 847,\n",
              " '0.7': 848,\n",
              " '/s/': 849,\n",
              " '3,204': 850,\n",
              " 'pharmaceutical': 851,\n",
              " '1.12': 852,\n",
              " '7.5': 853,\n",
              " 'collectability': 854,\n",
              " 'simplified': 855,\n",
              " 'Unless': 856,\n",
              " 'adequately': 857,\n",
              " 'NATURE': 858,\n",
              " 'introduces': 859,\n",
              " '9,116,908': 860,\n",
              " 'General': 861,\n",
              " 'OFFSETTING': 862,\n",
              " '198,000': 863,\n",
              " 'Xtandi': 864,\n",
              " 'RE44,940': 865,\n",
              " 'HRG': 866,\n",
              " 'exempt': 867,\n",
              " 'unfavorable': 868,\n",
              " '33,263': 869,\n",
              " 'Division': 870,\n",
              " 'warehousing': 871,\n",
              " 'Immediately': 872,\n",
              " '140': 873,\n",
              " '2,860,002': 874,\n",
              " 'ten': 875,\n",
              " 'Ridgefield': 876,\n",
              " '2,842': 877,\n",
              " 'Willmut': 878,\n",
              " '1.9': 879,\n",
              " '127,742': 880,\n",
              " '424,317': 881,\n",
              " 'coking': 882,\n",
              " 'upstream': 883,\n",
              " 'Many': 884,\n",
              " 'Facility': 885,\n",
              " 'acquirers': 886,\n",
              " 'three': 887,\n",
              " '25,685,832': 888,\n",
              " 'purchasers': 889,\n",
              " 'automatic': 890,\n",
              " 'authorized': 891,\n",
              " '44.0': 892,\n",
              " '10,937': 893,\n",
              " 'economic': 894,\n",
              " '72.9': 895,\n",
              " '91': 896,\n",
              " 'previous': 897,\n",
              " 'Committed': 898,\n",
              " '33.4': 899,\n",
              " 'military': 900,\n",
              " 'collection': 901,\n",
              " '4.3': 902,\n",
              " 'strategic': 903,\n",
              " '357.2': 904,\n",
              " 'flat': 905,\n",
              " '8-RELATED': 906,\n",
              " 'staying': 907,\n",
              " '42-Table': 908,\n",
              " 'binding': 909,\n",
              " 'royalties': 910,\n",
              " 'decommissioned': 911,\n",
              " 'Barbara': 912,\n",
              " 'triple': 913,\n",
              " 'Per': 914,\n",
              " 'Borrowers': 915,\n",
              " 'Realty': 916,\n",
              " '1,074.1': 917,\n",
              " 'trading': 918,\n",
              " 'enforce': 919,\n",
              " 'tier': 920,\n",
              " 'Sanford': 921,\n",
              " 'skilled': 922,\n",
              " 'allows': 923,\n",
              " '11,918': 924,\n",
              " '647': 925,\n",
              " 'come': 926,\n",
              " '26.0': 927,\n",
              " '70,852': 928,\n",
              " 'census': 929,\n",
              " 'Music': 930,\n",
              " 'tickets': 931,\n",
              " 'arbitration': 932,\n",
              " 'since': 933,\n",
              " 'latter': 934,\n",
              " 'alleges': 935,\n",
              " 'Power': 936,\n",
              " '14.00': 937,\n",
              " 'recommending': 938,\n",
              " '13': 939,\n",
              " '640': 940,\n",
              " '18,206': 941,\n",
              " 'assure': 942,\n",
              " 'invoiced': 943,\n",
              " 'large': 944,\n",
              " '1.05': 945,\n",
              " 'whereby': 946,\n",
              " 'Post': 947,\n",
              " '2,157': 948,\n",
              " 'identifiable': 949,\n",
              " 'Professions': 950,\n",
              " 'summarizes': 951,\n",
              " 'Chartered': 952,\n",
              " 'intention': 953,\n",
              " 'Invested': 954,\n",
              " 'In2016': 955,\n",
              " 'calculating': 956,\n",
              " 'cyberterrorism': 957,\n",
              " 'decommissioning': 958,\n",
              " '187,000': 959,\n",
              " 'ProjectsSDG': 960,\n",
              " 'Mandatory': 961,\n",
              " 'Concepts': 962,\n",
              " 'records': 963,\n",
              " 'immunity': 964,\n",
              " 'Duavee': 965,\n",
              " 'For': 966,\n",
              " '48.1': 967,\n",
              " 'Mr.': 968,\n",
              " 'Amneal': 969,\n",
              " 'Atlas': 970,\n",
              " 'leave': 971,\n",
              " 'follow': 972,\n",
              " '127.7': 973,\n",
              " '35': 974,\n",
              " 'processes': 975,\n",
              " 'obligation': 976,\n",
              " 'trucking': 977,\n",
              " 'NDT': 978,\n",
              " 'reflects': 979,\n",
              " 'Saturday': 980,\n",
              " '50.4': 981,\n",
              " 'Unpatented': 982,\n",
              " 'Receivable': 983,\n",
              " 'Minnesota': 984,\n",
              " 'piece': 985,\n",
              " 'Nonperforming': 986,\n",
              " 'acted': 987,\n",
              " '7,415,530': 988,\n",
              " 'investigation': 989,\n",
              " '561.7': 990,\n",
              " 'Russell': 991,\n",
              " '23,304': 992,\n",
              " 'Allergan': 993,\n",
              " 'presentational': 994,\n",
              " 'complying': 995,\n",
              " '650': 996,\n",
              " '4,948': 997,\n",
              " 'mid-2017': 998,\n",
              " 'candidly': 999,\n",
              " ...}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://nlp.stanford.edu/data/glove.6B.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fXHQc7xSv_L4",
        "outputId": "e8be2c11-47ed-4c34-8565-46089975ea0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-06-10 11:01:21--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2022-06-10 11:01:22--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  5.16MB/s    in 2m 40s  \n",
            "\n",
            "2022-06-10 11:04:02 (5.14 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip glove.6B.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GL3ouuT6wj_I",
        "outputId": "0726051d-0d22-4fd8-e034-9d02e4d24384"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  glove.6B.zip\n",
            "  inflating: glove.6B.50d.txt        \n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Word embeddings"
      ],
      "metadata": {
        "id": "5MYXqs034kL5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Easier to load with gensim\n",
        "WORD_DIM = 300\n",
        "from gensim.models import KeyedVectors\n",
        "#word2vec = KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True)\n",
        "\n",
        "# Glove\n",
        "from gensim.scripts.glove2word2vec import glove2word2vec\n",
        "_ = glove2word2vec('glove.6B.300d.txt', 'glove.6B.300d_w2v.txt')\n",
        "word2vec = KeyedVectors.load_word2vec_format('glove.6B.300d_w2v.txt', binary=False)"
      ],
      "metadata": {
        "id": "VvumPl5TxUpf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize randomly the word embedding matrix\n",
        "word_embeddings = np.random.rand(len(word2idx), WORD_DIM)\n",
        "\n",
        "# Set the values to 0 for padding\n",
        "word_embeddings[word2idx['_PAD_']] = np.zeros(WORD_DIM)\n",
        "\n",
        "# Copy from word2vec\n",
        "for word in vocabulary:\n",
        "  if word in word2vec:\n",
        "    word_embeddings[word2idx[word], :] = word2vec[word]\n",
        "word_embeddings.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kZCN28CaxWct",
        "outputId": "a56b7ffa-e4dc-4b84-e11b-311f9e81d0fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11558, 300)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use the attribute word_idx for all samples. In case a word is unknown, we will simply replace it with the work \"UNK\"."
      ],
      "metadata": {
        "id": "ie3mMc7Z4KUS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "49cTpBM37QS6"
      },
      "outputs": [],
      "source": [
        "# We add the word indeces to all data splits\n",
        "for split_data in [train_data.data, val_data.data, test_data.data]:\n",
        "  for idx, sample in split_data.items():\n",
        "    sample['word_idx'] = []\n",
        "    for token in sample['tokens']:\n",
        "      # If a word is not in our vocabulary, we put the UNK token instead\n",
        "      sample['word_idx'].append(word2idx[token] if token in word2idx else word2idx['_UNK_'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max(len(sample['tokens']) for idx, sample in train_data.data.items()), \\\n",
        "max(len(sample['tokens']) for idx, sample in val_data.data.items()), \\\n",
        "max(len(sample['tokens']) for idx, sample in test_data.data.items())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dW1_OM_20TTr",
        "outputId": "1c3efe1c-d625-46ac-8fc6-eb44926135be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(64, 64, 64)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The last step is to pad all entries to 64 tokens."
      ],
      "metadata": {
        "id": "HJyegy0l1mCQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PAD_LENGTH = 64\n",
        "\n",
        "for split_data in [train_data.data, val_data.data, test_data.data]:\n",
        "  for idx, sample in split_data.items():\n",
        "    while len(sample['word_idx']) < PAD_LENGTH:\n",
        "      sample['word_idx'].append(word2idx['_PAD_'])\n",
        "\n",
        "      # add special value -100 to exlude \"_PAD_\" prediction in the lost function.\n",
        "      sample['y_ners'].append(-100)\n",
        "\n",
        "    # Sanity check\n",
        "    assert len(sample['word_idx']) == PAD_LENGTH"
      ],
      "metadata": {
        "id": "8RODH_yL1uTG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Character embeddings"
      ],
      "metadata": {
        "id": "AEL3vLdQ4obw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_characters = set()\n",
        "for idx, sample in train_data.data.items():\n",
        "  for token in sample['tokens']:\n",
        "    for char in token:\n",
        "      all_characters.add(char)\n",
        "print(all_characters)"
      ],
      "metadata": {
        "id": "PBbk2r93G1KB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab0f9829-a147-492a-c1a1-855722cc5def"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Q', '5', 'D', \"'\", 'y', 'ó', '/', 'u', 'é', 'ñ', '▪', '·', 'p', 'N', 'w', '2', 'k', '-', 'K', 'i', '¼', 's', 'C', 't', 'v', 'O', '+', '\"', 'r', 'î', '”', 'Y', '%', 'V', 'o', 'W', 'q', '4', 'Z', 'j', '_', 'L', 'J', '&', 'H', '0', 'b', 'F', '’', 'á', '•', '£', '®', '3', 'g', '1', '8', '$', '*', '§', '“', '€', ')', '#', 'E', 'n', 'U', '(', 'h', '\\uf0b7', '!', '.', 'x', 'T', 'S', ',', ';', '9', 'z', 'í', 'M', 'G', 'I', 'X', 'c', '™', ';', 'R', 'P', 'A', 'l', '6', '7', 'e', 'f', 'm', ':', 'a', 'd', 'B'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "char2idx = {'_PAD_': 0, '_UNK_': 1}\n",
        "for char in all_characters:\n",
        "  char2idx[char] = len(char2idx)\n",
        "idx2char = {idx:char for char, idx in char2idx.items()}\n",
        "char2idx"
      ],
      "metadata": {
        "id": "pa67SeaUG-ll",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce66032c-6e43-44ca-835b-0df9ff6fe7fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'!': 72,\n",
              " '\"': 29,\n",
              " '#': 65,\n",
              " '$': 59,\n",
              " '%': 34,\n",
              " '&': 45,\n",
              " \"'\": 5,\n",
              " '(': 69,\n",
              " ')': 64,\n",
              " '*': 60,\n",
              " '+': 28,\n",
              " ',': 77,\n",
              " '-': 19,\n",
              " '.': 73,\n",
              " '/': 8,\n",
              " '0': 47,\n",
              " '1': 57,\n",
              " '2': 17,\n",
              " '3': 55,\n",
              " '4': 39,\n",
              " '5': 3,\n",
              " '6': 93,\n",
              " '7': 94,\n",
              " '8': 58,\n",
              " '9': 79,\n",
              " ':': 98,\n",
              " ';': 78,\n",
              " 'A': 91,\n",
              " 'B': 101,\n",
              " 'C': 24,\n",
              " 'D': 4,\n",
              " 'E': 66,\n",
              " 'F': 49,\n",
              " 'G': 83,\n",
              " 'H': 46,\n",
              " 'I': 84,\n",
              " 'J': 44,\n",
              " 'K': 20,\n",
              " 'L': 43,\n",
              " 'M': 82,\n",
              " 'N': 15,\n",
              " 'O': 27,\n",
              " 'P': 90,\n",
              " 'Q': 2,\n",
              " 'R': 89,\n",
              " 'S': 76,\n",
              " 'T': 75,\n",
              " 'U': 68,\n",
              " 'V': 35,\n",
              " 'W': 37,\n",
              " 'X': 85,\n",
              " 'Y': 33,\n",
              " 'Z': 40,\n",
              " '_': 42,\n",
              " '_PAD_': 0,\n",
              " '_UNK_': 1,\n",
              " 'a': 99,\n",
              " 'b': 48,\n",
              " 'c': 86,\n",
              " 'd': 100,\n",
              " 'e': 95,\n",
              " 'f': 96,\n",
              " 'g': 56,\n",
              " 'h': 70,\n",
              " 'i': 21,\n",
              " 'j': 41,\n",
              " 'k': 18,\n",
              " 'l': 92,\n",
              " 'm': 97,\n",
              " 'n': 67,\n",
              " 'o': 36,\n",
              " 'p': 14,\n",
              " 'q': 38,\n",
              " 'r': 30,\n",
              " 's': 23,\n",
              " 't': 25,\n",
              " 'u': 9,\n",
              " 'v': 26,\n",
              " 'w': 16,\n",
              " 'x': 74,\n",
              " 'y': 6,\n",
              " 'z': 80,\n",
              " '£': 53,\n",
              " '§': 61,\n",
              " '®': 54,\n",
              " '·': 13,\n",
              " '¼': 22,\n",
              " 'á': 51,\n",
              " 'é': 10,\n",
              " 'í': 81,\n",
              " 'î': 31,\n",
              " 'ñ': 11,\n",
              " 'ó': 7,\n",
              " ';': 88,\n",
              " '’': 50,\n",
              " '“': 62,\n",
              " '”': 32,\n",
              " '•': 52,\n",
              " '€': 63,\n",
              " '™': 87,\n",
              " '▪': 12,\n",
              " '\\uf0b7': 71}"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CHAR_DIM = 32\n",
        "\n",
        "# Initialize randomly the word embedding matrix\n",
        "char_embeddings = np.random.rand(len(idx2char), CHAR_DIM)\n",
        "\n",
        "# Set the values to 0 for padding\n",
        "char_embeddings[char2idx['_PAD_']] = np.zeros(CHAR_DIM)"
      ],
      "metadata": {
        "id": "YuyZbgx-HIil"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "longest_words = list(sorted({(len(token), token) for idx, sample in train_data.data.items() for token in sample['tokens']}, reverse=True))[:100]\n",
        "longest_words"
      ],
      "metadata": {
        "id": "lw2paa9VIjSP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a36cfb32-066f-4bed-f6f1-24d6476cbd01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(29, 'DISPOSITIONSAcquisitionsMarco'),\n",
              " (27, 'PresentationBusinessNoodles'),\n",
              " (21, 'www.malone-bailey.com'),\n",
              " (20, 'ProConnectProConnect'),\n",
              " (20, 'OPERATIONSSummaryThe'),\n",
              " (20, 'DivestituresHypackOn'),\n",
              " (19, 'EnerSysConsolidated'),\n",
              " (18, 'telecommunications'),\n",
              " (18, 'disproportionately'),\n",
              " (18, 'Telecommunications'),\n",
              " (18, 'IncidentOverviewOn'),\n",
              " (17, 'reclassifications'),\n",
              " (17, 'opportunistically'),\n",
              " (17, 'contemporaneously'),\n",
              " (17, 'commercialization'),\n",
              " (17, 'cardiorespiratory'),\n",
              " (17, 'Reclassifications'),\n",
              " (17, '2:16-cv-00255-TJH'),\n",
              " (16, 'unenforceability'),\n",
              " (16, 'underutilization'),\n",
              " (16, 'undercapitalized'),\n",
              " (16, 'uncollateralized'),\n",
              " (16, 'responsibilities'),\n",
              " (16, 'reclassification'),\n",
              " (16, 'recapitalization'),\n",
              " (16, 'misappropriation'),\n",
              " (16, 'indemnifications'),\n",
              " (16, 'extraterritorial'),\n",
              " (16, 'administratively'),\n",
              " (16, 'Reclassification'),\n",
              " (16, 'L.P.Consolidated'),\n",
              " (16, 'L.P.CONSOLIDATED'),\n",
              " (16, 'Indemnifications'),\n",
              " (16, 'Divestitures2017'),\n",
              " (15, 'unconditionally'),\n",
              " (15, 'technologically'),\n",
              " (15, 'retrospectively'),\n",
              " (15, 'representatives'),\n",
              " (15, 'representations'),\n",
              " (15, 'reconsideration'),\n",
              " (15, 'reconfiguration'),\n",
              " (15, 'reconciliations'),\n",
              " (15, 'recommendations'),\n",
              " (15, 'rationalization'),\n",
              " (15, 'polychlorinated'),\n",
              " (15, 'noncontributory'),\n",
              " (15, 'investigational'),\n",
              " (15, 'interpretations'),\n",
              " (15, 'instrumentation'),\n",
              " (15, 'ineffectiveness'),\n",
              " (15, 'indemnification'),\n",
              " (15, 'experimentation'),\n",
              " (15, 'diversification'),\n",
              " (15, 'discontinuation'),\n",
              " (15, 'deconsolidation'),\n",
              " (15, 'decommissioning'),\n",
              " (15, 'correspondingly'),\n",
              " (15, 'competitiveness'),\n",
              " (15, 'collateralizing'),\n",
              " (15, 'classifications'),\n",
              " (15, 'characteristics'),\n",
              " (15, 'categorizations'),\n",
              " (15, 'anticompetitive'),\n",
              " (15, 'accomplishments'),\n",
              " (15, 'Pricewaterhouse'),\n",
              " (15, 'Pharmaceuticals'),\n",
              " (15, 'EpiPenBeginning'),\n",
              " (15, 'Diversification'),\n",
              " (15, 'Decommissioning'),\n",
              " (15, 'Contemporaneous'),\n",
              " (15, 'Biotechnologies'),\n",
              " (15, 'Approximately57'),\n",
              " (15, '815-Derivatives'),\n",
              " (14, 'unsubordinated'),\n",
              " (14, 'unconsolidated'),\n",
              " (14, 'transportation'),\n",
              " (14, 'transformation'),\n",
              " (14, 'subcontractors'),\n",
              " (14, 'specifications'),\n",
              " (14, 'simultaneously'),\n",
              " (14, 'securitization'),\n",
              " (14, 'restructurings'),\n",
              " (14, 'responsibility'),\n",
              " (14, 'representative'),\n",
              " (14, 'reorganization'),\n",
              " (14, 'remeasurements'),\n",
              " (14, 'remanufactured'),\n",
              " (14, 'reincorporated'),\n",
              " (14, 'reimbursements'),\n",
              " (14, 'rehabilitation'),\n",
              " (14, 'recoverability'),\n",
              " (14, 'reconciliation'),\n",
              " (14, 'recommendation'),\n",
              " (14, 'reasonableness'),\n",
              " (14, 'questionnaires'),\n",
              " (14, 'qualifications'),\n",
              " (14, 'pronouncements'),\n",
              " (14, 'presentational'),\n",
              " (14, 'preacquisition'),\n",
              " (14, 'postretirement')]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will consider that a word has maximum 18 chars. In \n",
        "practice, there might be more preprocessing to do, which could potentially reduce noise."
      ],
      "metadata": {
        "id": "wSGslQ7VJecP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PAD_CHAR_LENGTH = 18\n",
        "\n",
        "for split_data in [train_data.data, val_data.data, test_data.data]:\n",
        "  for idx, sample in split_data.items():\n",
        "    sample['chars_idx'] = []\n",
        "    for token in sample['tokens']:\n",
        "      # We trunk in case we have more chars\n",
        "      chars = [(char2idx[char] if char in char2idx else char2idx['_UNK_']) for char in token][:PAD_CHAR_LENGTH]\n",
        "      \n",
        "      # Transform chars into indeces\n",
        "      sample['chars_idx'].append(chars)\n",
        "\n",
        "      # Pad chars with PAD tokens\n",
        "      while len(sample['chars_idx'][-1]) < PAD_CHAR_LENGTH:\n",
        "        sample['chars_idx'][-1].append(char2idx['_PAD_'])\n",
        "    \n",
        "    # Pad with empty chars to reach the padding length of the sentence\n",
        "    while len(sample['chars_idx']) < PAD_LENGTH:\n",
        "      sample['chars_idx'].append([0 for _ in range(PAD_CHAR_LENGTH)])\n",
        "    \n",
        "    # Sanity check\n",
        "    assert len(sample['chars_idx']) == PAD_LENGTH\n",
        "    for chars in sample['chars_idx']:\n",
        "      assert len(chars) == PAD_CHAR_LENGTH"
      ],
      "metadata": {
        "id": "Ze5zFEzQJcIl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modeling"
      ],
      "metadata": {
        "id": "T7eGYhur2vZu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RNN"
      ],
      "metadata": {
        "id": "X-ZrS83U20TG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Modeling"
      ],
      "metadata": {
        "id": "ug51dQF05Tfg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rMryBnYn8rF-"
      },
      "outputs": [],
      "source": [
        "class RNN_Model(nn.Module):\n",
        "    def __init__(self, dropout, hidden_dim, classes_num, words_num, word_dim, chars_num, char_dim):\n",
        "        super(RNN_Model, self).__init__()\n",
        "\n",
        "        self.word_embedding = nn.Embedding(num_embeddings=words_num, embedding_dim=word_dim)\n",
        "        \n",
        "        # Our main component\n",
        "        self.word_rnn = nn.RNN(input_size=word_dim,\n",
        "                               hidden_size=hidden_dim,\n",
        "                               num_layers=1,\n",
        "                               batch_first=True,\n",
        "                               dropout=0, # No dropout; it is complicated for RNNs. \n",
        "                               bidirectional=False)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.activation = nn.Tanh()\n",
        "\n",
        "        # The last layer to compute the probabilities for the output classes\n",
        "        self.final_layer = nn.Linear(in_features=hidden_dim, out_features=classes_num)\n",
        "\n",
        "        self.char_embedding = nn.Embedding(num_embeddings=chars_num, embedding_dim=char_dim)\n",
        "        self.char_rnn = nn.RNN(input_size=char_dim,\n",
        "                               hidden_size=hidden_dim,\n",
        "                               num_layers=1,\n",
        "                               batch_first=True,\n",
        "                               dropout=0, # No dropout; it is complicated for RNNs. Do you have an intuition why?\n",
        "                               bidirectional=False)\n",
        "        \n",
        "        \n",
        "    def forward(self, x):\n",
        "        x_words = self.word_embedding(x['word_idx']) # Convert into word embeddings\n",
        "\n",
        "        x_words = self.dropout(x_words)\n",
        "        \n",
        "        output, last_hidden_state = self.word_rnn(x_words)\n",
        "        \n",
        "        output = self.activation(output)\n",
        "        output = self.dropout(output)\n",
        "\n",
        "        logits = self.final_layer(output)\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5hPUwZKB16W"
      },
      "source": [
        "Let's see if our model can compute a foward pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T5MkMxsgBjiS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b64ecf0-40cb-4ea5-caf8-aff47f2e76bd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'word_idx': tensor([[0, 1, 2, 3, 4, 5]])}"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "# Example of a batch=1 and 6 word indeces\n",
        "input = {'word_idx': torch.tensor([[0,1,2,3,4,5]])}\n",
        "input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4zvOOdBRBizW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c494d797-bbed-4462-904b-7f9b75ed8795"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[[ 0.0764, -0.1668,  0.0908],\n",
              "          [ 0.1358, -0.1125, -0.0273],\n",
              "          [-0.2773, -0.3301,  0.0274],\n",
              "          [-0.1854, -0.0084,  0.3041],\n",
              "          [ 0.4168, -0.0840,  0.1346],\n",
              "          [-0.4787,  0.0061,  0.3210]]], grad_fn=<AddBackward0>),\n",
              " torch.Size([1, 6, 3]))"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "ner = RNN_Model(dropout=0.3, hidden_dim=50, classes_num=3, words_num=6, word_dim=10, chars_num=6, char_dim=5)\n",
        "logits = ner(input)\n",
        "logits, logits.size()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model seems to work and is able to compute the tag probability of a word."
      ],
      "metadata": {
        "id": "ZMQ43RVD47K8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Loss function**\n",
        "<br>\n",
        "What is the loss to use to optimize the model? Because we are doing classification, the most natural one is to use the [cross entropy loss](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html?highlight=cross%20entropy#torch.nn.CrossEntropyLoss). "
      ],
      "metadata": {
        "id": "HVbx59FSv-jw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss(reduction='mean', ignore_index=-100)"
      ],
      "metadata": {
        "id": "p3gvINhXv9T8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ATTENTION**: What is this ignore_index? In this can of task, where the output depends of the input length, we use PADDING. However, we do not want the prediction for the PAD words to have any influence. One way of doing this is to use a special value for the class (here -100) that will be ignored in the computation loss! See the documentation for more information."
      ],
      "metadata": {
        "id": "Y32AG89EwDul"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Metric**\n",
        "<br>\n",
        "As our task implies multi classification and the distribution of data is unbalanced originally, we will use the macro F1 score. Basically, it consists of the average F1 score for each class. (The micro F1 score applies a weighted average)."
      ],
      "metadata": {
        "id": "SX5XnPYtysfV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "def compute_f1(preds, golds):\n",
        "  return f1_score(preds, golds, average='macro')"
      ],
      "metadata": {
        "id": "I0Z-JxJqyvcL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training + Testing** "
      ],
      "metadata": {
        "id": "oU50d_P25LgX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 10\n",
        "\n",
        "# We initialize our model\n",
        "model = RNN_Model(dropout=0.3, \n",
        "                   hidden_dim=128, \n",
        "                   classes_num=class_num, \n",
        "                   words_num=len(word2idx), \n",
        "                   word_dim=WORD_DIM,\n",
        "                   chars_num=len(char2idx),\n",
        "                   char_dim=CHAR_DIM)\n",
        "\n",
        "# Copy the word embedding matrix\n",
        "model.word_embedding.weight.data = torch.from_numpy(word_embeddings).float()\n",
        "model.word_embedding.weight.requires_grad = False # We do NOT want to fine-tune the word embedding\n",
        "\n",
        "model.char_embedding.weight.data = torch.from_numpy(char_embeddings).float()\n",
        "model.char_embedding.weight.requires_grad = True # We DO want to fine-tune the char embedding as they were randomly initialized."
      ],
      "metadata": {
        "id": "151JZi2gVI0E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We initialize our optimizer to update the weights of the model\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-8) # L2 = weight_decay"
      ],
      "metadata": {
        "id": "ygMApFZ3VI0E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch"
      ],
      "metadata": {
        "id": "SOo_ljzmVdkO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We can load our dataset using a dataloader\n",
        "train_loader = DataLoader(\n",
        "        train_data,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle=True, # Pay attention that we can shuffle the samples for training\n",
        "        num_workers=0, # And specify how many working we want. 0/1 = 1\n",
        "        drop_last=False) # Finally, it is possible to drop the last batch if its size is smaller than args.batch_size. In some applications, it is easier to ignore it instead of handling it.\n",
        "\n",
        "val_loader = DataLoader(\n",
        "        val_data,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle=False, # Pay attention here that the data is not shuffled.\n",
        "        num_workers=0, \n",
        "        drop_last=False)\n",
        "\n",
        "test_loader = DataLoader(\n",
        "        test_data,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle=False, # Pay attention here that the data is not shuffled.\n",
        "        num_workers=0, \n",
        "        drop_last=False)"
      ],
      "metadata": {
        "id": "3F4n0k-DVI0F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Move the model to the device (CPU or GPU)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "# Initialize the loss function\n",
        "criterion = nn.CrossEntropyLoss(reduction='mean', ignore_index=-100)\n",
        "\n",
        "best_epoch = 0\n",
        "best_val_so_far = 0\n",
        "test_perf = 0\n",
        "\n",
        "\n",
        "# TRAINING LOOP\n",
        "for epoch in range(5):\n",
        "  print('------------------------------------------------------------------------')\n",
        "  print('Epoch: {}'.format(epoch))\n",
        "\n",
        "  # TRAIN\n",
        "  # We set the model in train mode. It will store information to compute the gradients\n",
        "  # Also, the implementation of dropout, batchnorm, etc is different at training and inference time.\n",
        "  model.train()\n",
        "\n",
        "  train_losses = []\n",
        " \n",
        "  for idx, batch in tqdm.tqdm(enumerate(train_loader), desc='Training'):\n",
        "    # move them to GPU\n",
        "    batch['word_idx'] = batch['word_idx'].to(device)\n",
        "    batch['chars_idx'] = batch['chars_idx'].to(device)\n",
        "    batch['y_ners'] = batch['y_ners'].to(device) #BxL\n",
        "\n",
        "    # Compute the model output and the loss\n",
        "    y_logits = model(batch)\n",
        "    # We have to \"flatten\" the predictions because CE only handle tensors like BxC and B\n",
        "    loss = criterion(y_logits.view(-1, class_num), batch['y_ners'].view(-1))\n",
        "\n",
        "    # Update model parameters\n",
        "    optimizer.zero_grad() # This is very important! By default, gradients are cumulated in tensors.\n",
        "    loss.backward() # Now that gradients have been empties, we compute the new ones using the loss.\n",
        "    optimizer.step() # We do gradient update with our optimization function (i.e., the weights of the model are updated).\n",
        "  \n",
        "    train_losses.append(loss.item())\n",
        "  \n",
        "  \n",
        "  # VAL + TEST\n",
        "  val_test_losses = {'val': [], 'test': []}\n",
        "  val_test_f1 = {'val': [], 'test': []}\n",
        "  \n",
        "  # Unlike before, we set the model in eval mode to compute correctly dropout, batchnorm etc\n",
        "  model.eval()\n",
        "\n",
        "  # We do not store information relative to gradients as we do not update the model.\n",
        "  # That's the reason why inference requires less memory and is faster.\n",
        "  with torch.no_grad():\n",
        "    for split_data, data in [('val', val_loader), ('test', test_loader)]:\n",
        "      # Pay attention how the data loading become easiers!\n",
        "      for idx, batch in tqdm.tqdm(enumerate(data), desc=split_data.capitalize()):\n",
        "\n",
        "        # move them to GPU\n",
        "        batch['word_idx'] = batch['word_idx'].to(device)\n",
        "        batch['chars_idx'] = batch['chars_idx'].to(device)\n",
        "        batch['y_ners'] = batch['y_ners'].to(device) #BxL\n",
        "\n",
        "        # Compute the model output and the loss\n",
        "        y_logits = model(batch) \n",
        "        # We have to \"flatten\" the predictions because CE only handle tensors like BxC and B\n",
        "        loss = criterion(y_logits.view(-1, class_num), batch['y_ners'].view(-1))\n",
        "\n",
        "        val_test_losses[split_data].append(loss.item())\n",
        "\n",
        "        # Compute the macro f1 to evaluate our model\n",
        "        y_probs = F.softmax(y_logits, dim=-1)\n",
        "        y_pred = torch.argmax(y_logits, dim=-1)\n",
        "\n",
        "        f1 = compute_f1(y_pred.view(-1).cpu().numpy(), batch['y_ners'].view(-1).cpu().numpy())\n",
        "        val_test_f1[split_data].append(f1)\n",
        "  \n",
        "  # Monitoring\n",
        "  print('Train loss: {:.4f}'.format(np.mean(train_losses)))\n",
        "  print('Val   loss: {:.4f}'.format(np.mean(val_test_losses['val'])))\n",
        "  print('Test  loss: {:.4f}'.format(np.mean(val_test_losses['test'])))\n",
        "  print()\n",
        "\n",
        "  val_f1 = np.mean(val_test_f1['val'])\n",
        "  test_f1 = np.mean(val_test_f1['test'])\n",
        "  print('Val   Macro F1: {:.4f}'.format(val_f1))\n",
        "  print('Test  Macro F1: {:.4f}'.format(test_f1))\n",
        "  print()\n",
        "\n",
        "  if best_val_so_far < val_f1:\n",
        "    best_val_so_far = val_f1\n",
        "    test_perf = test_f1\n",
        "    best_epoch = epoch\n",
        "  \n",
        "  print('Best Epoch: {}, best val macro F1: {:.4f}, test macro F1: {:.4f}'.format(best_epoch, best_val_so_far, test_perf))\n",
        "  print()\n",
        "  print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_TpqSESgD3wv",
        "outputId": "8ebcca61-4735-49d0-a3ce-cd55e04b671b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------------------------------------------------\n",
            "Epoch: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 1500it [00:32, 46.25it/s]\n",
            "Val: 350it [00:03, 92.40it/s]\n",
            "Test: 350it [00:04, 80.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 0.1183\n",
            "Val   loss: 0.0658\n",
            "Test  loss: 0.0644\n",
            "\n",
            "Val   Macro F1: 0.2371\n",
            "Test  Macro F1: 0.2374\n",
            "\n",
            "Best Epoch: 0, best val macro F1: 0.2371, test macro F1: 0.2374\n",
            "\n",
            "\n",
            "------------------------------------------------------------------------\n",
            "Epoch: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 1500it [00:32, 46.45it/s]\n",
            "Val: 350it [00:03, 93.45it/s]\n",
            "Test: 350it [00:03, 90.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 0.0579\n",
            "Val   loss: 0.0631\n",
            "Test  loss: 0.0611\n",
            "\n",
            "Val   Macro F1: 0.2373\n",
            "Test  Macro F1: 0.2376\n",
            "\n",
            "Best Epoch: 1, best val macro F1: 0.2373, test macro F1: 0.2376\n",
            "\n",
            "\n",
            "------------------------------------------------------------------------\n",
            "Epoch: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 1500it [00:32, 46.32it/s]\n",
            "Val: 350it [00:03, 93.34it/s]\n",
            "Test: 350it [00:03, 93.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 0.0531\n",
            "Val   loss: 0.0581\n",
            "Test  loss: 0.0566\n",
            "\n",
            "Val   Macro F1: 0.2383\n",
            "Test  Macro F1: 0.2414\n",
            "\n",
            "Best Epoch: 2, best val macro F1: 0.2383, test macro F1: 0.2414\n",
            "\n",
            "\n",
            "------------------------------------------------------------------------\n",
            "Epoch: 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 1500it [00:33, 44.36it/s]\n",
            "Val: 350it [00:03, 88.08it/s]\n",
            "Test: 350it [00:03, 88.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 0.0498\n",
            "Val   loss: 0.0591\n",
            "Test  loss: 0.0572\n",
            "\n",
            "Val   Macro F1: 0.2384\n",
            "Test  Macro F1: 0.2408\n",
            "\n",
            "Best Epoch: 3, best val macro F1: 0.2384, test macro F1: 0.2408\n",
            "\n",
            "\n",
            "------------------------------------------------------------------------\n",
            "Epoch: 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 1500it [00:33, 44.90it/s]\n",
            "Val: 350it [00:03, 90.95it/s]\n",
            "Test: 350it [00:03, 92.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 0.0481\n",
            "Val   loss: 0.0578\n",
            "Test  loss: 0.0562\n",
            "\n",
            "Val   Macro F1: 0.2379\n",
            "Test  Macro F1: 0.2408\n",
            "\n",
            "Best Epoch: 3, best val macro F1: 0.2384, test macro F1: 0.2408\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LSTM"
      ],
      "metadata": {
        "id": "_nRjoarC6cdw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocabulary = list(set(vocab for li in train_data['tokens'] for vocab in li))\n",
        "vocabulary.append(\"endpad\")\n",
        "num_vocab = len(vocabulary)"
      ],
      "metadata": {
        "id": "CDF56OkNysOI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "finer = load_dataset(\"nlpaueb/finer-139\")\n",
        "ner_tags = finer.features[f\"ner_tags\"].feature.names\n",
        "num_ner_tags = len(ner_tags)"
      ],
      "metadata": {
        "id": "5jig_RgwzdTG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ner_tags"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AsY5Vt6J1IgA",
        "outputId": "4f995237-3796-45f1-9a93-1da0d3b99464"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['O',\n",
              " 'B-AccrualForEnvironmentalLossContingencies',\n",
              " 'B-AcquiredFiniteLivedIntangibleAssetsWeightedAverageUsefulLife',\n",
              " 'I-AcquiredFiniteLivedIntangibleAssetsWeightedAverageUsefulLife',\n",
              " 'B-AllocatedShareBasedCompensationExpense',\n",
              " 'B-AmortizationOfFinancingCosts',\n",
              " 'B-AmortizationOfIntangibleAssets',\n",
              " 'I-AmortizationOfIntangibleAssets',\n",
              " 'B-AntidilutiveSecuritiesExcludedFromComputationOfEarningsPerShareAmount',\n",
              " 'I-AntidilutiveSecuritiesExcludedFromComputationOfEarningsPerShareAmount',\n",
              " 'B-AreaOfRealEstateProperty',\n",
              " 'I-AreaOfRealEstateProperty',\n",
              " 'B-AssetImpairmentCharges',\n",
              " 'B-BusinessAcquisitionEquityInterestsIssuedOrIssuableNumberOfSharesIssued',\n",
              " 'B-BusinessAcquisitionPercentageOfVotingInterestsAcquired',\n",
              " 'I-BusinessAcquisitionPercentageOfVotingInterestsAcquired',\n",
              " 'B-BusinessCombinationAcquisitionRelatedCosts',\n",
              " 'B-BusinessCombinationConsiderationTransferred1',\n",
              " 'B-BusinessCombinationContingentConsiderationLiability',\n",
              " 'B-BusinessCombinationRecognizedIdentifiableAssetsAcquiredAndLiabilitiesAssumedIntangibleAssetsOtherThanGoodwill',\n",
              " 'B-BusinessCombinationRecognizedIdentifiableAssetsAcquiredAndLiabilitiesAssumedIntangibles',\n",
              " 'B-CapitalizedContractCostAmortization',\n",
              " 'B-CashAndCashEquivalentsFairValueDisclosure',\n",
              " 'B-ClassOfWarrantOrRightExercisePriceOfWarrantsOrRights1',\n",
              " 'B-CommonStockCapitalSharesReservedForFutureIssuance',\n",
              " 'B-CommonStockDividendsPerShareDeclared',\n",
              " 'B-CommonStockParOrStatedValuePerShare',\n",
              " 'B-CommonStockSharesAuthorized',\n",
              " 'I-CommonStockSharesAuthorized',\n",
              " 'B-CommonStockSharesOutstanding',\n",
              " 'B-ConcentrationRiskPercentage1',\n",
              " 'B-ContractWithCustomerLiability',\n",
              " 'B-ContractWithCustomerLiabilityRevenueRecognized',\n",
              " 'B-CumulativeEffectOfNewAccountingPrincipleInPeriodOfAdoption',\n",
              " 'B-DebtInstrumentBasisSpreadOnVariableRate1',\n",
              " 'B-DebtInstrumentCarryingAmount',\n",
              " 'B-DebtInstrumentConvertibleConversionPrice1',\n",
              " 'B-DebtInstrumentFaceAmount',\n",
              " 'I-DebtInstrumentFaceAmount',\n",
              " 'B-DebtInstrumentFairValue',\n",
              " 'B-DebtInstrumentInterestRateEffectivePercentage',\n",
              " 'B-DebtInstrumentInterestRateStatedPercentage',\n",
              " 'B-DebtInstrumentMaturityDate',\n",
              " 'I-DebtInstrumentMaturityDate',\n",
              " 'B-DebtInstrumentRedemptionPricePercentage',\n",
              " 'B-DebtInstrumentTerm',\n",
              " 'I-DebtInstrumentTerm',\n",
              " 'B-DebtInstrumentUnamortizedDiscount',\n",
              " 'B-DebtWeightedAverageInterestRate',\n",
              " 'B-DeferredFinanceCostsGross',\n",
              " 'B-DeferredFinanceCostsNet',\n",
              " 'B-DefinedBenefitPlanContributionsByEmployer',\n",
              " 'B-DefinedContributionPlanCostRecognized',\n",
              " 'B-Depreciation',\n",
              " 'B-DerivativeFixedInterestRate',\n",
              " 'B-DerivativeNotionalAmount',\n",
              " 'B-DisposalGroupIncludingDiscontinuedOperationConsideration',\n",
              " 'B-EffectiveIncomeTaxRateContinuingOperations',\n",
              " 'B-EffectiveIncomeTaxRateReconciliationAtFederalStatutoryIncomeTaxRate',\n",
              " 'B-EmployeeServiceShareBasedCompensationNonvestedAwardsTotalCompensationCostNotYetRecognized',\n",
              " 'B-EmployeeServiceShareBasedCompensationNonvestedAwardsTotalCompensationCostNotYetRecognizedPeriodForRecognition1',\n",
              " 'I-EmployeeServiceShareBasedCompensationNonvestedAwardsTotalCompensationCostNotYetRecognizedPeriodForRecognition1',\n",
              " 'B-EmployeeServiceShareBasedCompensationNonvestedAwardsTotalCompensationCostNotYetRecognizedShareBasedAwardsOtherThanOptions',\n",
              " 'B-EmployeeServiceShareBasedCompensationTaxBenefitFromCompensationExpense',\n",
              " 'B-EquityMethodInvestmentOwnershipPercentage',\n",
              " 'I-EquityMethodInvestmentOwnershipPercentage',\n",
              " 'B-EquityMethodInvestments',\n",
              " 'B-FiniteLivedIntangibleAssetUsefulLife',\n",
              " 'I-FiniteLivedIntangibleAssetUsefulLife',\n",
              " 'B-GainsLossesOnExtinguishmentOfDebt',\n",
              " 'B-Goodwill',\n",
              " 'B-GoodwillImpairmentLoss',\n",
              " 'B-GuaranteeObligationsMaximumExposure',\n",
              " 'B-IncomeLossFromEquityMethodInvestments',\n",
              " 'B-IncomeTaxExpenseBenefit',\n",
              " 'B-InterestExpense',\n",
              " 'B-InterestExpenseDebt',\n",
              " 'B-LeaseAndRentalExpense',\n",
              " 'B-LesseeOperatingLeaseRenewalTerm',\n",
              " 'I-LesseeOperatingLeaseRenewalTerm',\n",
              " 'B-LesseeOperatingLeaseTermOfContract',\n",
              " 'I-LesseeOperatingLeaseTermOfContract',\n",
              " 'B-LettersOfCreditOutstandingAmount',\n",
              " 'B-LineOfCredit',\n",
              " 'B-LineOfCreditFacilityCommitmentFeePercentage',\n",
              " 'B-LineOfCreditFacilityCurrentBorrowingCapacity',\n",
              " 'B-LineOfCreditFacilityInterestRateAtPeriodEnd',\n",
              " 'B-LineOfCreditFacilityMaximumBorrowingCapacity',\n",
              " 'B-LineOfCreditFacilityRemainingBorrowingCapacity',\n",
              " 'B-LineOfCreditFacilityUnusedCapacityCommitmentFeePercentage',\n",
              " 'B-LongTermDebt',\n",
              " 'B-LongTermDebtFairValue',\n",
              " 'B-LossContingencyAccrualAtCarryingValue',\n",
              " 'B-LossContingencyDamagesSoughtValue',\n",
              " 'B-LossContingencyEstimateOfPossibleLoss',\n",
              " 'B-LossContingencyPendingClaimsNumber',\n",
              " 'I-LossContingencyPendingClaimsNumber',\n",
              " 'B-MinorityInterestOwnershipPercentageByNoncontrollingOwners',\n",
              " 'B-MinorityInterestOwnershipPercentageByParent',\n",
              " 'B-NumberOfOperatingSegments',\n",
              " 'B-NumberOfRealEstateProperties',\n",
              " 'I-NumberOfRealEstateProperties',\n",
              " 'B-NumberOfReportableSegments',\n",
              " 'B-OperatingLeaseCost',\n",
              " 'B-OperatingLeaseExpense',\n",
              " 'B-OperatingLeaseLiability',\n",
              " 'B-OperatingLeasePayments',\n",
              " 'B-OperatingLeaseRightOfUseAsset',\n",
              " 'B-OperatingLeaseWeightedAverageDiscountRatePercent',\n",
              " 'B-OperatingLeaseWeightedAverageRemainingLeaseTerm1',\n",
              " 'I-OperatingLeaseWeightedAverageRemainingLeaseTerm1',\n",
              " 'B-OperatingLeasesRentExpenseNet',\n",
              " 'B-OperatingLossCarryforwards',\n",
              " 'B-PaymentsToAcquireBusinessesGross',\n",
              " 'B-PaymentsToAcquireBusinessesNetOfCashAcquired',\n",
              " 'B-PreferredStockDividendRatePercentage',\n",
              " 'B-PreferredStockSharesAuthorized',\n",
              " 'I-PreferredStockSharesAuthorized',\n",
              " 'B-ProceedsFromIssuanceOfCommonStock',\n",
              " 'B-PropertyPlantAndEquipmentUsefulLife',\n",
              " 'I-PropertyPlantAndEquipmentUsefulLife',\n",
              " 'B-PublicUtilitiesRequestedRateIncreaseDecreaseAmount',\n",
              " 'B-RelatedPartyTransactionAmountsOfTransaction',\n",
              " 'I-RelatedPartyTransactionAmountsOfTransaction',\n",
              " 'B-RelatedPartyTransactionExpensesFromTransactionsWithRelatedParty',\n",
              " 'I-RelatedPartyTransactionExpensesFromTransactionsWithRelatedParty',\n",
              " 'B-RepaymentsOfDebt',\n",
              " 'B-RestructuringAndRelatedCostExpectedCost1',\n",
              " 'B-RestructuringCharges',\n",
              " 'B-RevenueFromContractWithCustomerExcludingAssessedTax',\n",
              " 'B-RevenueFromContractWithCustomerIncludingAssessedTax',\n",
              " 'B-RevenueFromRelatedParties',\n",
              " 'B-RevenueRemainingPerformanceObligation',\n",
              " 'B-Revenues',\n",
              " 'B-SaleOfStockNumberOfSharesIssuedInTransaction',\n",
              " 'I-SaleOfStockNumberOfSharesIssuedInTransaction',\n",
              " 'B-SaleOfStockPricePerShare',\n",
              " 'B-ShareBasedCompensation',\n",
              " 'B-ShareBasedCompensationArrangementByShareBasedPaymentAwardAwardVestingPeriod1',\n",
              " 'I-ShareBasedCompensationArrangementByShareBasedPaymentAwardAwardVestingPeriod1',\n",
              " 'B-ShareBasedCompensationArrangementByShareBasedPaymentAwardEquityInstrumentsOtherThanOptionsGrantsInPeriod',\n",
              " 'I-ShareBasedCompensationArrangementByShareBasedPaymentAwardEquityInstrumentsOtherThanOptionsGrantsInPeriod',\n",
              " 'B-ShareBasedCompensationArrangementByShareBasedPaymentAwardEquityInstrumentsOtherThanOptionsGrantsInPeriodWeightedAverageGrantDateFairValue',\n",
              " 'B-ShareBasedCompensationArrangementByShareBasedPaymentAwardEquityInstrumentsOtherThanOptionsNonvestedNumber',\n",
              " 'B-ShareBasedCompensationArrangementByShareBasedPaymentAwardEquityInstrumentsOtherThanOptionsVestedInPeriodTotalFairValue',\n",
              " 'B-ShareBasedCompensationArrangementByShareBasedPaymentAwardNumberOfSharesAuthorized',\n",
              " 'I-ShareBasedCompensationArrangementByShareBasedPaymentAwardNumberOfSharesAuthorized',\n",
              " 'B-ShareBasedCompensationArrangementByShareBasedPaymentAwardNumberOfSharesAvailableForGrant',\n",
              " 'B-ShareBasedCompensationArrangementByShareBasedPaymentAwardOptionsExercisesInPeriodTotalIntrinsicValue',\n",
              " 'B-ShareBasedCompensationArrangementByShareBasedPaymentAwardOptionsGrantsInPeriodGross',\n",
              " 'B-ShareBasedCompensationArrangementByShareBasedPaymentAwardOptionsGrantsInPeriodWeightedAverageGrantDateFairValue',\n",
              " 'B-SharePrice',\n",
              " 'B-SharebasedCompensationArrangementBySharebasedPaymentAwardAwardVestingRightsPercentage',\n",
              " 'I-SharebasedCompensationArrangementBySharebasedPaymentAwardAwardVestingRightsPercentage',\n",
              " 'B-SharebasedCompensationArrangementBySharebasedPaymentAwardExpirationPeriod',\n",
              " 'I-SharebasedCompensationArrangementBySharebasedPaymentAwardExpirationPeriod',\n",
              " 'B-StockIssuedDuringPeriodSharesNewIssues',\n",
              " 'I-StockIssuedDuringPeriodSharesNewIssues',\n",
              " 'B-StockRepurchaseProgramAuthorizedAmount1',\n",
              " 'B-StockRepurchaseProgramRemainingAuthorizedRepurchaseAmount1',\n",
              " 'B-StockRepurchasedAndRetiredDuringPeriodShares',\n",
              " 'B-StockRepurchasedDuringPeriodShares',\n",
              " 'I-StockRepurchasedDuringPeriodShares',\n",
              " 'B-SupplementalInformationForPropertyCasualtyInsuranceUnderwritersPriorYearClaimsAndClaimsAdjustmentExpense',\n",
              " 'B-TreasuryStockAcquiredAverageCostPerShare',\n",
              " 'B-TreasuryStockSharesAcquired',\n",
              " 'I-TreasuryStockSharesAcquired',\n",
              " 'B-TreasuryStockValueAcquiredCostMethod',\n",
              " 'B-UnrecognizedTaxBenefits',\n",
              " 'B-UnrecognizedTaxBenefitsThatWouldImpactEffectiveTaxRate',\n",
              " 'I-DeferredFinanceCostsGross',\n",
              " 'I-CommonStockParOrStatedValuePerShare',\n",
              " 'I-LossContingencyEstimateOfPossibleLoss',\n",
              " 'I-DefinedContributionPlanCostRecognized',\n",
              " 'I-DebtInstrumentFairValue',\n",
              " 'I-ContractWithCustomerLiabilityRevenueRecognized',\n",
              " 'I-RevenueRemainingPerformanceObligation',\n",
              " 'I-EmployeeServiceShareBasedCompensationNonvestedAwardsTotalCompensationCostNotYetRecognized',\n",
              " 'I-DebtInstrumentInterestRateStatedPercentage',\n",
              " 'I-OperatingLossCarryforwards',\n",
              " 'I-MinorityInterestOwnershipPercentageByNoncontrollingOwners',\n",
              " 'I-InterestExpense',\n",
              " 'I-LongTermDebt',\n",
              " 'I-ShareBasedCompensation',\n",
              " 'I-DebtWeightedAverageInterestRate',\n",
              " 'I-DebtInstrumentCarryingAmount',\n",
              " 'I-DebtInstrumentConvertibleConversionPrice1',\n",
              " 'I-IncomeTaxExpenseBenefit',\n",
              " 'I-ShareBasedCompensationArrangementByShareBasedPaymentAwardOptionsGrantsInPeriodWeightedAverageGrantDateFairValue',\n",
              " 'I-EmployeeServiceShareBasedCompensationNonvestedAwardsTotalCompensationCostNotYetRecognizedShareBasedAwardsOtherThanOptions',\n",
              " 'I-EquityMethodInvestments',\n",
              " 'I-DebtInstrumentUnamortizedDiscount',\n",
              " 'I-GainsLossesOnExtinguishmentOfDebt',\n",
              " 'I-ShareBasedCompensationArrangementByShareBasedPaymentAwardNumberOfSharesAvailableForGrant',\n",
              " 'I-BusinessCombinationRecognizedIdentifiableAssetsAcquiredAndLiabilitiesAssumedIntangibleAssetsOtherThanGoodwill',\n",
              " 'I-PreferredStockDividendRatePercentage',\n",
              " 'I-RevenueFromContractWithCustomerIncludingAssessedTax',\n",
              " 'I-OperatingLeaseWeightedAverageDiscountRatePercent',\n",
              " 'I-LineOfCredit',\n",
              " 'I-LineOfCreditFacilityMaximumBorrowingCapacity',\n",
              " 'I-EffectiveIncomeTaxRateReconciliationAtFederalStatutoryIncomeTaxRate',\n",
              " 'I-LineOfCreditFacilityCommitmentFeePercentage',\n",
              " 'I-BusinessCombinationConsiderationTransferred1',\n",
              " 'I-CommonStockDividendsPerShareDeclared',\n",
              " 'I-DebtInstrumentBasisSpreadOnVariableRate1',\n",
              " 'I-DisposalGroupIncludingDiscontinuedOperationConsideration',\n",
              " 'I-ShareBasedCompensationArrangementByShareBasedPaymentAwardOptionsGrantsInPeriodGross',\n",
              " 'I-CommonStockSharesOutstanding',\n",
              " 'I-AmortizationOfFinancingCosts',\n",
              " 'I-LineOfCreditFacilityCurrentBorrowingCapacity',\n",
              " 'I-TreasuryStockValueAcquiredCostMethod',\n",
              " 'I-ShareBasedCompensationArrangementByShareBasedPaymentAwardEquityInstrumentsOtherThanOptionsNonvestedNumber',\n",
              " 'I-DebtInstrumentInterestRateEffectivePercentage',\n",
              " 'I-SaleOfStockPricePerShare',\n",
              " 'I-CapitalizedContractCostAmortization',\n",
              " 'I-RestructuringCharges',\n",
              " 'I-ShareBasedCompensationArrangementByShareBasedPaymentAwardEquityInstrumentsOtherThanOptionsVestedInPeriodTotalFairValue',\n",
              " 'I-AccrualForEnvironmentalLossContingencies',\n",
              " 'I-CashAndCashEquivalentsFairValueDisclosure',\n",
              " 'I-ProceedsFromIssuanceOfCommonStock',\n",
              " 'I-Revenues',\n",
              " 'I-BusinessCombinationRecognizedIdentifiableAssetsAcquiredAndLiabilitiesAssumedIntangibles',\n",
              " 'I-LettersOfCreditOutstandingAmount',\n",
              " 'I-ShareBasedCompensationArrangementByShareBasedPaymentAwardEquityInstrumentsOtherThanOptionsGrantsInPeriodWeightedAverageGrantDateFairValue',\n",
              " 'I-OperatingLeasePayments',\n",
              " 'I-LineOfCreditFacilityRemainingBorrowingCapacity',\n",
              " 'I-PaymentsToAcquireBusinessesGross',\n",
              " 'I-TreasuryStockAcquiredAverageCostPerShare',\n",
              " 'I-DeferredFinanceCostsNet',\n",
              " 'I-StockRepurchaseProgramAuthorizedAmount1',\n",
              " 'I-InterestExpenseDebt',\n",
              " 'I-ContractWithCustomerLiability',\n",
              " 'I-OperatingLeaseExpense',\n",
              " 'I-Depreciation',\n",
              " 'I-AllocatedShareBasedCompensationExpense',\n",
              " 'I-LossContingencyAccrualAtCarryingValue',\n",
              " 'I-LineOfCreditFacilityUnusedCapacityCommitmentFeePercentage',\n",
              " 'I-SupplementalInformationForPropertyCasualtyInsuranceUnderwritersPriorYearClaimsAndClaimsAdjustmentExpense',\n",
              " 'I-OperatingLeaseLiability',\n",
              " 'I-RevenueFromRelatedParties',\n",
              " 'I-PaymentsToAcquireBusinessesNetOfCashAcquired',\n",
              " 'I-BusinessCombinationContingentConsiderationLiability',\n",
              " 'I-LossContingencyDamagesSoughtValue',\n",
              " 'I-NumberOfOperatingSegments',\n",
              " 'I-BusinessAcquisitionEquityInterestsIssuedOrIssuableNumberOfSharesIssued',\n",
              " 'I-OperatingLeaseRightOfUseAsset',\n",
              " 'I-BusinessCombinationAcquisitionRelatedCosts',\n",
              " 'I-UnrecognizedTaxBenefits',\n",
              " 'I-GuaranteeObligationsMaximumExposure',\n",
              " 'I-RestructuringAndRelatedCostExpectedCost1',\n",
              " 'I-DefinedBenefitPlanContributionsByEmployer',\n",
              " 'I-OperatingLeaseCost',\n",
              " 'I-DerivativeFixedInterestRate',\n",
              " 'I-Goodwill',\n",
              " 'I-GoodwillImpairmentLoss',\n",
              " 'I-CommonStockCapitalSharesReservedForFutureIssuance',\n",
              " 'I-StockRepurchasedAndRetiredDuringPeriodShares',\n",
              " 'I-EmployeeServiceShareBasedCompensationTaxBenefitFromCompensationExpense',\n",
              " 'I-IncomeLossFromEquityMethodInvestments',\n",
              " 'I-NumberOfReportableSegments',\n",
              " 'I-LongTermDebtFairValue',\n",
              " 'I-RepaymentsOfDebt',\n",
              " 'I-ConcentrationRiskPercentage1',\n",
              " 'I-DebtInstrumentRedemptionPricePercentage',\n",
              " 'I-CumulativeEffectOfNewAccountingPrincipleInPeriodOfAdoption',\n",
              " 'I-SharePrice',\n",
              " 'I-UnrecognizedTaxBenefitsThatWouldImpactEffectiveTaxRate',\n",
              " 'I-ShareBasedCompensationArrangementByShareBasedPaymentAwardOptionsExercisesInPeriodTotalIntrinsicValue',\n",
              " 'I-EffectiveIncomeTaxRateContinuingOperations',\n",
              " 'I-RevenueFromContractWithCustomerExcludingAssessedTax',\n",
              " 'I-StockRepurchaseProgramRemainingAuthorizedRepurchaseAmount1',\n",
              " 'I-LineOfCreditFacilityInterestRateAtPeriodEnd',\n",
              " 'I-ClassOfWarrantOrRightExercisePriceOfWarrantsOrRights1',\n",
              " 'I-OperatingLeasesRentExpenseNet',\n",
              " 'I-LeaseAndRentalExpense',\n",
              " 'I-PublicUtilitiesRequestedRateIncreaseDecreaseAmount',\n",
              " 'I-MinorityInterestOwnershipPercentageByParent',\n",
              " 'I-AssetImpairmentCharges',\n",
              " 'I-DerivativeNotionalAmount']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = data['tokens']\n",
        "tags = data['ner_tags']"
      ],
      "metadata": {
        "id": "4MNCoHwfSadZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word2idx = {w: i + 1 for i, w in enumerate(vocabulary)}"
      ],
      "metadata": {
        "id": "CE_6R01EJnK-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tag2idx = {t: i for i, t in enumerate(ner_tags)}"
      ],
      "metadata": {
        "id": "e-q00PXXJEwG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#define Mappings between Sentences and Tags\n",
        "sentences = []\n",
        "\n",
        "for to in tokens:\n",
        "  for ta in tags:\n",
        "    sentences.append(list(zip(to, ta)))"
      ],
      "metadata": {
        "id": "ObHxoPIrooOc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QI7HQ4Sdq1nB",
        "outputId": "3f897c15-7946-4136-bfe3-f4e828cc111e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('The', 0),\n",
              " ('changes', 0),\n",
              " ('in', 0),\n",
              " ('the', 0),\n",
              " ('fair', 0),\n",
              " ('value', 0),\n",
              " ('of', 0),\n",
              " ('the', 0),\n",
              " ('derivatives', 0),\n",
              " ('and', 0),\n",
              " ('the', 0),\n",
              " ('related', 0),\n",
              " ('underlying', 0),\n",
              " ('foreign', 0),\n",
              " ('currency', 0),\n",
              " ('exposures', 0),\n",
              " ('resulted', 0),\n",
              " ('in', 0),\n",
              " ('net', 0),\n",
              " ('gains', 0),\n",
              " ('of', 0),\n",
              " ('$', 0),\n",
              " ('11', 0),\n",
              " ('million', 0),\n",
              " ('and', 0),\n",
              " ('$', 0),\n",
              " ('23', 0),\n",
              " ('million', 0),\n",
              " ('for', 0),\n",
              " ('the', 0),\n",
              " ('three', 0),\n",
              " ('months', 0),\n",
              " ('ended', 0),\n",
              " ('March', 0),\n",
              " ('31', 0),\n",
              " (',', 0),\n",
              " ('2020', 0),\n",
              " ('and', 0),\n",
              " ('2019', 0),\n",
              " (',', 0),\n",
              " ('respectively', 0),\n",
              " (',', 0),\n",
              " ('that', 0),\n",
              " ('are', 0),\n",
              " ('recognized', 0),\n",
              " ('in', 0),\n",
              " ('Other', 0),\n",
              " (',', 0),\n",
              " ('net', 0),\n",
              " ('expenses', 0),\n",
              " ('on', 0),\n",
              " ('the', 0),\n",
              " ('Consolidated', 0),\n",
              " ('Statements', 0),\n",
              " ('of', 0),\n",
              " ('Income', 0),\n",
              " ('.', 0),\n",
              " ('5', 0),\n",
              " ('.', 0)]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = 64\n",
        "\n",
        "#padding Input Sentences\n",
        "X = [[word2idx[w[0]] for w in s] for s in sentences]\n",
        "X = pad_sequences(maxlen=max_len, sequences=X, padding=\"post\", value=num_vocab-1)"
      ],
      "metadata": {
        "id": "Vry9J6BRUFVC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = [[w[1] for w in s] for s in sentences]\n",
        "y = pad_sequences(maxlen=max_len, sequences=y, padding=\"post\", value=tag2idx[\"O\"])"
      ],
      "metadata": {
        "id": "oVNSpwSk60Ks"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)"
      ],
      "metadata": {
        "id": "H1Is2spJ7F6z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_word = Input(shape=(max_len,))\n",
        "model = Embedding(input_dim=num_vocab, output_dim=64, input_length=max_len)(input_word)\n",
        "model = SpatialDropout1D(0.1)(model)"
      ],
      "metadata": {
        "id": "v_niUWW27Pru"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Bidirectional(LSTM(units=100, return_sequences=True, recurrent_dropout=0.1))(model)\n",
        "out = TimeDistributed(Dense(num_ner_tags, activation=\"softmax\"))(model)\n",
        "model = Model(input_word, out)"
      ],
      "metadata": {
        "id": "OFwb1TGeYY7U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8abcd825-2f1a-48a0-9b38-4ade6ebd4add"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=\"adam\",\n",
        "              loss=\"sparse_categorical_crossentropy\",\n",
        "              metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "20we4G_17eU8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "chkpt = ModelCheckpoint(\"model_weights.h5\", monitor='val_loss',verbose=1, save_best_only=True, save_weights_only=True, mode='min')\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=1, verbose=0, mode='max', baseline=None, restore_best_weights=False)\n",
        "\n",
        "#callbacks = [PlotLossesCallback(), chkpt, early_stopping]\n",
        "\n",
        "history = model.fit(\n",
        "    x=x_train,\n",
        "    y=y_train,\n",
        "    validation_data=(x_test,y_test),\n",
        "    batch_size=32, \n",
        "    epochs=3,\n",
        "    #callbacks=callbacks,\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "id": "Z3qAOErP7qT2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae879f20-4ce1-4723-c195-90598c61effa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "100000/100000 [==============================] - 18495s 185ms/step - loss: 0.0244 - accuracy: 0.9974 - val_loss: 0.0221 - val_accuracy: 0.9970\n",
            "Epoch 2/3\n",
            "100000/100000 [==============================] - 18617s 186ms/step - loss: 0.0221 - accuracy: 0.9974 - val_loss: 0.0215 - val_accuracy: 0.9970\n",
            "Epoch 3/3\n",
            "100000/100000 [==============================] - 18599s 186ms/step - loss: 0.0222 - accuracy: 0.9974 - val_loss: 0.0212 - val_accuracy: 0.9970\n",
            "CPU times: user 20h 16min 28s, sys: 1h 48min 41s, total: 22h 5min 9s\n",
            "Wall time: 15h 28min 31s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(x_test, y_test)"
      ],
      "metadata": {
        "id": "G1JSmRr67vEt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "794d5fe6-3366-4f24-aaf7-4fa72c767f93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25000/25000 [==============================] - 909s 36ms/step - loss: 0.0212 - accuracy: 0.9970\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.021217001602053642, 0.9969900250434875]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transformer"
      ],
      "metadata": {
        "id": "59d5MX-C6jdk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")"
      ],
      "metadata": {
        "id": "TMNSr8uHQNkh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "c7349514ba954dc78e5abab863e1e966",
            "531333c742014a80a7c3c181f31631ac",
            "354f5a9f03d941f5b417b5dc8315e7fc",
            "3a193747a27e44b0976bca54d0e5ce06",
            "5ef9979fc154449dac6559bdf71c77ca",
            "6c8a79d51b13453db4189ad7529b9e72",
            "d936abe574544bfdbe591753ff237380",
            "ed96f23e432c4a2a8209bfc150b9d8de",
            "62555751c2bf42c3947634512ce4e490",
            "573ce300d4c046559c30eb918242cf43",
            "ec20988834cc41299a3afeff5191b50a",
            "a4c3573b8d4140fba83cdde806994343",
            "e351d7240b4e46ae9ca88f2f948894ae",
            "ad4f87d1c76745fb9358d6e50677ffad",
            "c12b26c7996b4cd1ae417bfc3ebe2521",
            "85abe23aff414d0a935f6af08a80f996",
            "08681ba360db4864b0ea03f92018c6c7",
            "da980125c0a2436985947859ad921360",
            "9b6f8b851e4e463b9a909f326cb13aac",
            "9f56365c9a8e4ecdab52fd6528efa622",
            "c2e860f6af034de8ae00fbcfc017d868",
            "45318fe451c24db7b2c01e66529eabe9",
            "0db83b4c8dad4fddbab5273b26e25080",
            "92271d13a6a44d069c510824c7a5890f",
            "7386548245e846d99df7a1e1c431dcb6",
            "35b88a7e0f354522b6c81722c975254a",
            "aa017977900349b08f5948f87c6fe83c",
            "9a6365f164b643b4863134b91c335786",
            "a0849a1e6bf846d2b42b9dda0206e179",
            "73d8c882b7d648f1ade3ad05cc83f36c",
            "fb1257a9aae14fe4a4b2d6e0759c8e90",
            "734149b2fb9d4669a70857718f383a56",
            "206484c23d39468bbed035b57863c7a3",
            "d230101e409e47e2b5cdfab6b64a2bdf",
            "b898130d7f874ff784ad4718b06502bd",
            "22ac9c151b2849a186065ac80521bfea",
            "2ff3e998f7a44e4aba4883872b41b4de",
            "cdfab077d4924bb09693bfb02533b097",
            "d99b15d35faa4a57a1e21bb9f866df02",
            "950bdd24784a453d9ca12c03457ac190",
            "a8fd5bbdd49541e69fe2ebc4c2b510b8",
            "b83a262a9aa64c859ab747257e7887f5",
            "03b1fcf5101045478eaac07cc49fb351",
            "b1a2f94c7177425fbc5f95a8c4b25603"
          ]
        },
        "outputId": "ffedbb1b-8ec8-4531-c280-0dba0d3c877c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c7349514ba954dc78e5abab863e1e966"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/483 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a4c3573b8d4140fba83cdde806994343"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0db83b4c8dad4fddbab5273b26e25080"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/455k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d230101e409e47e2b5cdfab6b64a2bdf"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_and_align_labels(examples):\n",
        "    tokenized_inputs = tokenizer(examples[\"tokens\"], truncation=True, is_split_into_words=True)\n",
        "\n",
        "    labels = []\n",
        "    for i, label in enumerate(examples[f\"ner_tags\"]):\n",
        "        word_ids = tokenized_inputs.word_ids(batch_index=i)  # Map tokens to their respective word.\n",
        "        previous_word_idx = None\n",
        "        label_ids = []\n",
        "        for word_idx in word_ids:  # Set the special tokens to -100.\n",
        "            if word_idx is None:\n",
        "                label_ids.append(-100)\n",
        "            elif word_idx != previous_word_idx:  # Only label the first token of a given word.\n",
        "                label_ids.append(label[word_idx])\n",
        "            else:\n",
        "                label_ids.append(-100)\n",
        "            previous_word_idx = word_idx\n",
        "        labels.append(label_ids)\n",
        "\n",
        "    tokenized_inputs[\"labels\"] = labels\n",
        "    return tokenized_inputs"
      ],
      "metadata": {
        "id": "ej7FSCJmVgWj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_train_tokenized = data_train.map(tokenize_and_align_labels, batched=True)\n",
        "data_test_tokenized = data_test.map(tokenize_and_align_labels, batched=True)\n",
        "data_valid_tokenized = data_valid.map(tokenize_and_align_labels, batched=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "2905b9f509c84cb7820388e219fbc4c9",
            "9f9f0b95bff94a1eb6e2748a9ed923ec",
            "4c4a6b7aac52477cb2090af426510711",
            "c7831313807d4af5ab57cd182b227802",
            "a562bcdd739c4de9a089a782792fca8d",
            "863fc5d17ad74b4fb1424d3f1d205d8c",
            "f8cadbcda2ae4f21a1366333eb6ca3e3",
            "9f1c98f717524c83ae2e5a3f6794baf4",
            "45c637ddff3242748890ca64bdd1f858",
            "f16116caf5784bafa99e02177d655921",
            "7b82bd182c5d4b519298a1ba080847ee",
            "468fa73cfc9448fda5c391c3be613925",
            "091f2affa5a941a4b7e1a60e38da8830",
            "4fec13c439da42149c84b01db32c10b8",
            "d306afa2a7e245c1bed948c861c483cf",
            "9c57d46baf81430da0f69e9e183b107a",
            "7d241ee807e44966a0a7290d6ad33dd7",
            "99aae56e82424a708f5c6b380ea19f9f",
            "a5cd03ccad814d718512adf927f396f7",
            "48b7e8e99b3b4488ae88c328d3a7c3c5",
            "74a4fa85f1324c32b2736f63d045f6dd",
            "aff77ed2739748fa98d8e52974e9de70",
            "b955757e9e3e44dba6b87c96c83f444f",
            "07391ab755084d68a63de5005a0a092d",
            "a48874bf19ef4059a9ada29baa36d650",
            "49f1bafa05404c479a774d263d21f951",
            "034c94898a7d45f5b876c66c6998d133",
            "f1fc6d4f44104d5ebc460d35c185de04",
            "25cfb127015a46efa1447c3c057aa0e9",
            "4d137e049e394b1fae30860965b30245",
            "546c1ca02f114bf4a79be78a3c886bec",
            "5acce3563e1e4804a4d7707baf737af5",
            "4bb12cf1a0024d4fafed70788dd608f3"
          ]
        },
        "id": "6zi9FduDW_fz",
        "outputId": "b7e9ce1c-1263-465f-e07c-3f412aeeb5d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/15 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2905b9f509c84cb7820388e219fbc4c9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "468fa73cfc9448fda5c391c3be613925"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b955757e9e3e44dba6b87c96c83f444f"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)\n",
        "\n",
        "model = AutoModelForTokenClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=len(label_list))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139,
          "referenced_widgets": [
            "82627a0b88a648ab9d8acac9eee7a5ed",
            "64d25f9aeea44fc389ebc7dad959a8c0",
            "9da3733f8f094ebe9bd98e32015572e6",
            "2f80450874a44be78efae9bb093f8da8",
            "ed962ce7b6c54ef49492654e1b17153a",
            "8618deb528f74390af02af8688641e42",
            "eb13b5d03f834619ac00a8b6bc1d565e",
            "8d3440d4cc0b42aab48a67af8a0120e7",
            "d1185e898be94cabbd3b0e94fd9347ef",
            "9bbad44348f7425b828ca58e6bafcf2b",
            "41660269c77b43feb64cfadc055772be"
          ]
        },
        "id": "LmlAdZS8WETS",
        "outputId": "3c93ccbd-9754-4df8-8e7a-615e0ce229a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/256M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "82627a0b88a648ab9d8acac9eee7a5ed"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForTokenClassification: ['vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_transform.bias', 'vocab_transform.weight', 'vocab_projector.bias', 'vocab_projector.weight']\n",
            "- This IS expected if you are initializing DistilBertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "\n",
        "\n",
        "args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    evaluation_strategy = \"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01\n",
        ")"
      ],
      "metadata": {
        "id": "kKTc3yMGWqU6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "    model,\n",
        "    args,\n",
        "    train_dataset = data_train_tokenized.select(range(5000)),\n",
        "    eval_dataset = data_test_tokenized.select(range(500)),\n",
        "    data_collator=data_collator,\n",
        "    tokenizer=tokenizer\n",
        ")"
      ],
      "metadata": {
        "id": "vRGbcJCJfA7d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 674
        },
        "id": "ClE9nG9PfM7V",
        "outputId": "6bc316e6-f4b9-4c55-d8fc-e5ba2356024d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the training set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: ner_tags, tokens, id. If ner_tags, tokens, id are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 5000\n",
            "  Num Epochs = 3\n",
            "  Instantaneous batch size per device = 64\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 237\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='237' max='237' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [237/237 1:20:15, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.098765</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.095106</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.078951</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: ner_tags, tokens, id. If ner_tags, tokens, id are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 500\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: ner_tags, tokens, id. If ner_tags, tokens, id are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 500\n",
            "  Batch size = 64\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: ner_tags, tokens, id. If ner_tags, tokens, id are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 500\n",
            "  Batch size = 64\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=237, training_loss=0.35482530553632646, metrics={'train_runtime': 4845.7416, 'train_samples_per_second': 3.096, 'train_steps_per_second': 0.049, 'total_flos': 288254788298064.0, 'train_loss': 0.35482530553632646, 'epoch': 3.0})"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Summary"
      ],
      "metadata": {
        "id": "2GEU4OdlG0PP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is my first time training deep learning mdoels and I realized that deep learning models are way more complicated than machine learning models and they require much more resources. It takes a long time to train a deep learning model and my colab notebook has crashed multiple times due to insufficient RAM. It took me multiple days to make the codes work. I would have loved to train the models better and dive deeper into the details, but unfortunately, with the time constraint, I could only apply the basics of the models and present how the models work with the chosen dataset. \n",
        "<br> \n",
        "<br> **Comparison of Models**\n",
        "<br> RNN processes data sequentially and can process any length input. However, it is not very good at handling long sequences as it forgets contents of distant position. \n",
        "<br> LSTM is nowadays the replacement of RNN cells and it includes the forget gate, input gate and output gate. It is better than RNN because the gates determine which information should be remembered and which should be forgot. \n",
        "<br> BERT is chosen in the Transformer model. It contains encoder layers and self-attention heads. By jointly conditioning on both left and right context in all layers, it is designed to pre-train deep bidirectional representations from text."
      ],
      "metadata": {
        "id": "Np9Yg7QTG3vC"
      }
    }
  ]
}